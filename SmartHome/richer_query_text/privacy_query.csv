,text
0," Privacy attitudes and privacy behaviour: A review of current research on the privacy paradox phenomenon Privacy attitudes and privacy behaviour: A review of current research on the privacy paradox phenomenon Spyros Kokolakis * Department of Information & Communication Systems Engineering, University of the Aegean, Samos 83200, Greece A R T I C L E I N F O Article history: Received 10 February 2015 Received in revised form 10 June 2015 Accepted 6 July 2015 Available online 10 July 2015 A B S T R A C T Do people really care about their privacy? Surveys show that privacy is a primary concern for citizens in the digital age. On the other hand, individuals reveal personal information for relatively small rewards, often just for drawing the attention of peers in an online social network. This inconsistency of privacy attitudes and privacy behaviour is often referred to as the “privacy paradox”. In this paper, we present the results of a review of research lit- erature on the privacy paradox. We analyse studies that provide evidence of a paradoxical dichotomy between attitudes and behaviour and studies that challenge the existence of such a phenomenon.The diverse research results are explained by the diversity in research methods, the different contexts and the different conceptualisations of the privacy paradox. We also present several interpretations of the privacy paradox, stemming from social theory, psy- chology, behavioural economics and, in one case, from quantum theory. We conclude that current research has improved our understanding of the privacy paradox phenomenon. It is, however, a complex phenomenon that requires extensive further research. Thus, we call for synthetic studies to be based on comprehensive theoretical models that take into account the diversity of personal information and the diversity of privacy concerns. We suggest that future studies should use evidence of actual behaviour rather than self-reported behaviour. © 2015 Elsevier Ltd. All rights reserved. Keywords: Privacy Personal information Information privacy Privacy behaviour Privacy paradox 1. Introduction Anecdotal and empirical evidence indicate that individuals are willing to trade their personal information for relatively small rewards. For example, Carrascal et al. (2013) have found that internet users value their online browsing history for about 7 Euros, which is the equivalent a Big Mac meal.1 On the other hand, surveys of internet users’ attitudes show that users are highly concerned about their privacy and the collection and use of their personal information (e.g., TRUSTe, 2014, Pew Research Center, 2014). This dichotomy of information privacy attitude and actual behaviour has been coined the term “privacy paradox” (Brown, 2001; Norberg et al., 2007) or, to be more ac- curate, “information privacy paradox”. The privacy paradox has significant implications for e-commerce, e-government, online social networking, as well as for government privacy regulation. E-commerce and online social networking sites are collectors of vast amounts of per- sonal information. A proof of the privacy paradox would encourage them to increase the collection and use of per- sonal information. Government policy makers, on the other * Tel.: +302273082233. E-mail address: sak@aegean.gr http://dx.doi.org/10.1016/j.cose.2015.07.002 0167-4048/© 2015 Elsevier Ltd. All rights reserved. 1 It refers to the cost of a Big Mac meal in Spain, circa 2011 (Carrascal et al., 2013). c om pu t e r s & s e cu r i t y 6 4 ( 2 0 1 7 ) 1 2 2 – 1 3 4 Available online at www.sciencedirect.com journal homepage: www.elsevier.com/ locate /cose ScienceDirect mailto:sak@aegean.gr http://www.sciencedirect.com/science/journal/01674048 http://www.elsevier.com/locate/COSE http://crossmark.crossref.org/dialog/?doi=10.1016/j.cose.2015.07.002&domain=pdf hand, justify privacy regulation on people’s raised privacy con- cerns. The inconsistency between privacy attitude and actual behaviour weakens this justification. Several researchers have attempted to test the privacy paradox hypothesis and to find an explanation for this “para- doxical” phenomenon. Unfortunately, relevant research provides contradicting results and incomplete explanations. In this paper, we survey current literature with an aim to investigate the fol- lowing research questions: • Does the information privacy paradox exist? • What explains the dichotomy between privacy attitude and privacy behaviour? After the introduction, the paper continues with present- ing the scope and method of the literature review. In Section 3, we analyse studies that provide evidence for and against the privacy paradox hypothesis and provide explanations for this controversy. In Section 4, we present studies that suggest and explore different interpretations of the privacy paradox phe- nomenon. Finally, in Section 5 we discuss our results and provide recommendations for future research. 2. Literature review: scope and methodology We may distinguish three aspects of privacy (Holvast, 1993; Rosenberg, 1992): (a) territorial privacy, which is concerned with the physical area surrounding a person, (b) privacy of a person, which refers to the protection of a person against undue in- terference, such as physical search, and (c) informational privacy, which is concerned with controlling whether and how per- sonal data can be gathered, stored, processed, and disseminated. The scope of this literature review is restricted to the third aspect of privacy, informational privacy. Privacy paradox is used in this paper as a shortcut for the more accurate term infor- mational privacy paradox. In most relevant studies privacy paradox refers to the di- chotomy between privacy attitude and privacy behaviour. Some researchers, however, compare privacy concerns with privacy behaviour. The two constructs, privacy concerns and privacy at- titudes, though closely related, are fundamentally different. Privacy concerns could be quite generic and, in most cases, are not bound to any specific context, whilst privacy attitudes refer to the appraisal of specific privacy behaviours. In this litera- ture review we have included research papers that follow both approaches. Another distinction to be made is between privacy behaviour and privacy intention. Several studies measure privacy inten- tion instead of privacy behaviour. These studies overlook an essential aspect of the paradox, the fact that often privacy in- tentions do not lead to protective behaviour. Despite that, they were also included in this literature review. Current literature includes a few studies that attribute a com- pletely different meaning to the term privacy paradox as referring to the tension between personalisation and privacy, especially in e-commerce. It is also often named the personalisation-privacy paradox. For example, Sutanto et al. (2013) examined the impact of IT-enabled personalisation and personalised marketing on smartphone users’ privacy concerns and proposed a personalised, privacy-safe application that retains users’ information locally on their smartphones while still providing them with personalised product messages. In addition, there is a body of literature that is concerned with the legal and ethical aspects of the privacy paradox. All these studies were excluded. The first stage in our search for the literature involved identifying papers on privacy paradox in the Scopus database. Using these keywords, 53 articles were listed as relating to the privacy paradox. In the preliminary screening, we removed articles that were anonymous, erratum notifications and edi- torials. We also removed articles on legal and ethical aspects of the privacy paradox. Finally, we excluded articles con- cerned with the personalisation-privacy paradox.The remaining list included 22 articles. Scopus is a comprehensive database that covers more than 21,000 peer-reviewed journals, as well as several thousands of scientific conferences proceedings and scientific books. A similar search in Thomson’s Web of Science database did not contribute any additional relevant articles. In the second stage, we further investigated the refer- ences list of the papers identified in the first stage. Papers selected from those references lists were also screened fol- lowing the same criteria as in the first stage and their references lists were investigated to identify additional relevant papers. Through this process we collected 29 articles. Most of them do not use the term privacy paradox and for this reason they were not identified in the first stage. Our final list of articles for this literature review comprised 51 articles. We believe that our review covers most of the literature pertaining to the privacy paradox and includes all significant research articles on the topic. 3. The debate about the privacy paradox 3.1. Early studies In 2001, a study of internet use explored online shopping popu- larity and the concerns of users with regard to privacy and security, among other issues (Brown, 2001). Through a series of in-depth interviews with online shoppers, Brown uncov- ered “something of a ‘privacy paradox’”. While individuals expressed their concerns about their privacy being infringed, they were still willing to give their personal details to online retailers as long as they had something to gain in return. Interviewees said they were afraid that too much informa- tion about them was collected, but this would not stop them from buying online. They also reported that they were using loyalty cards lured by the discounts and gifts offered by several stores. These findings were consistent with previous re- search on loyalty cards that showed that shoppers were willing to trade information about their grocery purchases for cost savings at the cash register (Sayre and Horne, 2000). In the same year, Spiekermann et al. (2001) presented the results of a study aiming to reveal the relation between privacy preferences and actual behaviour in the context of e-commerce. They conducted an experiment to compare self-reported privacy preferences with actual disclosing behaviour during online shopping. Participants were first asked to complete a 123c om pu t e r s & s e cu r i t y 6 4 ( 2 0 1 7 ) 1 2 2 – 1 3 4 questionnaire on privacy attitudes and preferences and, then, to visit an online store. During their shopping in the store they were engaged in a sales dialogue with an anthropomorphic 3-D shopping bot. Participants answered a majority of questions, even if these were highly personal. This indicates that even though internet users claim that privacy is a high priority, they do not behave accordingly. More evidence of an attitude vs. behaviour dichotomy and some preliminary interpretations of the phenomenon were pro- vided by researchers following the behaviour economics approach. Acquisti (2004) claims that “[p]eople may not be able to act as economically rational agents when it comes to personal privacy.” He argues that privacy-related decisions are affected by in- complete information, bounded rationality and psychological biases, such as confirmation bias, hyperbolic discounting and others.These decision-making biases have been well documented in the behavioural economics literature (e.g., Gilovich et al., 2002). Acquisti built an economic model that partly explains privacy attitude – behaviour inconsistencies. This model incorpo- rates the immediate gratification bias. Immediate gratification refers to the tendency to value present benefits more than future risks. Thus, in individuals’ heuristic assessment, the present benefits of information disclosure outweigh the future privacy risks. Furthermore, he argued that sophisticated privacy advocates might realise that protecting themselves from any possible privacy intrusion is unrealistic. Thus, they might not be willing to adopt a strict privacy protection strategy, since they doubt it will eventually pay-off (Acquisti, 2004). Stepping from economic theory into empirical research, Acquisti and Grossklags (2005) collected survey data that support the hypothesis that privacy decision-making is affected by in- complete information, bounded rationality and psychological biases. They also found evidence of a privacy attitude vs. behaviour dichotomy. Whilst most of the subjects (approx. 89%) reported to be either moderately or very concerned about privacy, more than 21% of the sample admitted to having re- vealed their social security number for discounts or better services or recommendations, and more than 28% had given their phone numbers to merchants, raffle organisers and so forth. Another stream of research aimed to understand the self- disclosing behaviour in online social networks, especially among young people. Barnes (2006) uses the term privacy paradox in reference to the privacy behaviour of young people in Social Networking Sites (SNSs). Young people tend not to realise that SNSs provide a public space and disclose personal informa- tion that could possibly be misused. The term privacy paradox was mainly established by Norberg et al. (2007). They conducted two studies, each comprising two phases. In the first phase they asked a sample of students about their willingness to disclose specific pieces of information. Phase two took place several weeks later, when subjects were asked to provide the same kind of information to a market re- searcher. This study confirmed the hypothesis that individuals would actually disclose a significantly greater amount of per- sonal information than their stated intentions indicate. In a second study that followed the same methodology they tested the effect of risk perceptions on stated intentions to disclose per- sonal information and the effect of trust perceptions on actual privacy behaviour. They found evidence that support the risk–intention relation, but they did not find support for the trust–behaviour relation hypothesis. 3.2. Evidence supporting vs. evidence challenging the existence of the privacy paradox Preliminary evidence by Spiekermann et al. (2001), Acquisti and Grossklags (2005) and Norberg et al. (2007) were further sup- ported by research in both transactional situations, such as e-commerce, and social situations, as in the case of online social networks. Studies that aimed to determine a value for personal in- formation have indicated very low valuations that do not justify the high privacy concerns expressed by people in polls and surveys. Huberman et al. (2005) conducted a series of experi- mental auctions to elicit the value people place on their private data. In these auctions participants named a price for their data and the person that demanded the least was paid the second- lowest demanded price (i.e., a reverse second-price auction). The information that was put on auction was weight and age. The average demand price for age was $57.56 vs. $74.06 for weight. The experiment also revealed a tendency for a higher valuation of weight information when it is perceived as em- barrassing. Also, as expected, very young people were more willing to reveal their age than older ones. In another experiment subjects faced trade-off situations, where they were asked to choose between incomplete privacy protection and benefits such as convenience or promotions (Hann et al., 2007). It was estimated that protection against errors in personal records, improper access of personal infor- mation and secondary use of personal information is worth between $30.49 and $44.62. Beresford et al. (2012) conducted a field experiment, in which subjects were asked to buy a DVD from one of two compet- ing stores. The two stores were almost identical. The first store asked for income and date of birth, whilst the second store asked for favourite colour and year of birth. Obviously, the in- formation requested by the first store is significantly more sensitive. Nevertheless, when the price was the same sub- jects bought from both stores equally often. When the price was set to be 1 Euro less in the first store, almost all partici- pants chose the cheaper store, although it was asking more sensitive information. A post-experimental questionnaire tested if subjects were unconcerned about privacy issues. 75% of par- ticipants indicated that they had a strong interest in data protection and 95% said that they were interested in the pro- tection of their personal information. Carrascal et al. (2013) conducted an experiment aiming to determine the monetary value of several types of personal in- formation. Using a web browser plugin they prompted users to value their personal data at the time and place they were gen- erated. In the first phase of the experiment, the browser plugin collected data about the browsing behaviour of each subject.These data were used to calibrate the behaviour of the plugin in the second phase. In the second phase the plugin displayed popups as the participants were browsing the internet. Popups con- tained two kinds of questions: questions about valuating personal information and questions on participants’ privacy percep- tions and knowledge. Information valuation questions were framed as auctions. For example, one question was “What is the 124 c om pu t e r s & s e cu r i t y 6 4 ( 2 0 1 7 ) 1 2 2 – 1 3 4 minimum amount of money you would accept for selling 10 of the photos you have uploaded to this website to a private company?” The experiment was concluded with a post-study questionnaire. The results of this study show significantly low evaluations of personal information. Users value their brows- ing history at 7 Euros on average.With regard to offline personal information, such as age, address, and economic status, average valuation is approximately 25 Euros. Users gave higher valua- tions to data relating to interactions in social networks (12 Euros) and finance websites (15.5 Euros), when compared with activi- ties such as search (2 Euros) and shopping (5 Euros). On the other hand, it appears that consumers are willing to pay a premium for privacy, albeit a small one. Egelman et al. (2012) performed two experiments with smartphone users and found that when choosing among applications with similar functionality, privacy-conscious participants were willing to pay a premium of $1.50 over an initial price of $0.49. However, this occurred only when users were presented the requested per- missions of each application side-by-side. Another stream of research has focused on online social net- works and the relationship between privacy concerns and information disclosure in SNSs. Tufekci (2008) reports the results of a questionnaire survey aiming to study students’ self- disclosure behaviour in SNSs. The study found little to no relationship between online privacy concerns and informa- tion disclosure. Another interesting result is that students manage their concerns about unwanted audience by adjust- ing the visibility of information, but not by regulating the levels of disclosure. Reynolds et al. (2011) in their study also found that there was little correlation between participants’ broader concern about privacy on Facebook and their posting behaviour. Contrary to Tufekci (2008) they found that the portion of posts that were visible to a large audience appeared to be indepen- dent of general privacy attitude. Hughes-Roberts (2013), based on a questionnaire survey and an examination of partici- pants’ Facebook profiles, concluded that a general statement of user concern is not a valid indicator of privacy behaviour within the network. However, he questioned the appropriate- ness of surveys as instruments for studying the privacy paradox. A web survey by Taddicken (2014) also showed that privacy concerns hardly impact self-disclosure. The relation between privacy concerns and self-disclosure is moderated by various variables. In particular, perceived social relevance and the number of other social web applications used have a strong moderating effect. In this study social relevance mainly refers to the disclosing behaviour of communication partners indicating that disclosure proceeds in a quid pro quo basis, i.e. “you tell me and I tell you”. Lee et al. (2013) also confirmed the existence of an attitude vs. behaviour dichotomy. They conducted a series of semi- structured in-depth interviews and an experiment to assess the influence of expected benefit and expected risk on users’ in- tention to share personal information.They concluded that users actively share personal information despite their concerns, because they do not only consider risk but also the expected benefit of sharing. A study by Zafeiropoulou et al. (2013) specifically exam- ined location data, which is a form of personal information increasingly used by mobile applications. Their survey also found evidence that supports the existence of privacy paradox for location data. Finally, Oomen and Leenes (2008) studied privacy risk perception in relation to the use of privacy en- hancing technologies. Their survey data indicate that a high perception of privacy risk is an insufficient motivator for people to adopt privacy protecting strategies, while knowing these exist. All the aforementioned studies provide evidence that support the hypothesis of a paradoxical dichotomy between privacy at- titudes and privacy behaviour. Nevertheless, several researchers have provided evidence that raise doubts about the existence of a privacy paradox. Individuals disclose personal information when they see some benefit to it, but, at the same time, they are significantly affected by the way this information is handled. They are significantly concerned about secondary use of per- sonal data and these concerns do lead to a cautious behaviour. The absence of secondary disclosure has a stronger influ- ence than a 10% price cut, and is just 8% lower than a 25% price cut, according to a study by D’Souza and Phelps (2009).They con- ducted two online surveys to study the influence of price and secondary use on purchase likelihood and concluded that privacy concerns do matter and there is a measurable relationship with purchase behaviour.This study uses online questionnaires, rather than factual purchase data, which limits the validity of results. A survey of visitors in two commercial websites (Wakefield, 2013) also provided evidence that supports the hypothesis that perceived website trust is an important determinant of con- sumers’ intention to disclose personal information. Also, when privacy policies are displayed prominently, con- sumers tend to purchase from online retailers that better protect their privacy. Tsai et al. (2011) conducted a two-phase study that involved an online concerns survey and an online shop- ping experiment. In the experiment they used a shopping search engine that compactly displays privacy policy information.They found that consumers provided with salient privacy informa- tion take that information into account and make purchases from online shops that offer medium or high levels of privacy protection.They conclude that “…contrary to the common view that consumers are unlikely to pay for privacy, consumers may be willing to pay a premium for privacy.” In the realm of online social networks several studies chal- lenge the common assumption that young people do not protect their private information. Young people use a variety of pro- tection strategies, such as using pseudonyms and giving false information (Miltgen and Peyrat-Guillard, 2014), restricting access to their profiles and adjusting their privacy settings (boyd and Hargittai, 2010), limiting friendship requests, and delet- ing tags and photos (Young and Quan-Haase, 2013). Information disclosure and information control in online social networks are not closely related. Disclosure is driven by the need for popularity, which explains why young people tend to disclose personal information. On the other hand, low levels of trust lead to control strategies, such as denying friend requests in order to control who has access to personal profiles (Christofides et al., 2009). Privacy-concerned users may employ various privacy- protection responses. Son and Kim (2008) provide a taxonomy of Information Privacy-Protective Responses (IPPRs) that in- cludes the following six types of IPPRs: refusal (i.e. users refuse to provide information), misrepresentation (i.e. users provide false information), removal of information from online com- panies databases, negative word-of-mouth, complaining directly to online companies, and complaining indirectly to third-party 125c om pu t e r s & s e cu r i t y 6 4 ( 2 0 1 7 ) 1 2 2 – 1 3 4 organisations. They also conducted a survey that revealed a strong correlation between information privacy concern and all types of responses, except for misrepresentation. Moreover, contrary to previous research, Blank et al. (2014) found that younger people are more likely to take action to protect their privacy than older ones. In addition, studies show a positive correlation between privacy concerns and protection behaviour. Lutz and Strathoff (2014) conducted a telephone survey in Switzerland employing a questionnaire that covered several privacy-related constructs. This survey confirmed a weak but statistically significant influence of privacy concerns on protection behaviour. Recent surveys show that privacy concerns trigger protec- tive responses, such as uninstalling mobile applications. A survey of smartphone users by the Pew Internet Project (Boyles et al., 2012) revealed that 54% of mobile application users have decided to not install a cell phone application when they discovered how much personal information they would need to share in order to use it and 30% of cell phone application users have uninstalled an application that was already on their cell phone because they learned it was collecting personal information that they did not wish to share. On the other hand, only 19% of cell phone owners have turned off the location tracking feature on their cell phone. Table 1 provides a list of the studies that provide evidence that support the privacy paradox hypothesis and Table 2 lists the studies that provide evidence that challenge it. Table 1 – Studies that provide evidence that support the privacy paradox hypothesis. Study Context Methodology Participants Acquisti (2004) e-Commerce Conceptual/analytic Not applicable (not an empirical research) Acquisti and Grossklags (2005) e-Commerce Survey Students and graduates (mean age 24) Barnes (2006) SNSs Students survey/ literature review Students Beresford et al. (2012) Online shopping Experiment Mainly students Brown (2001) Online shopping In-depth interviews Internet users (mean age 28) Carrascal et al. (2013) Email/entertainment/finance/ news/search/e-shopping/SNSs Survey Web users (mean age 32) Egelman et al. (2012) Smartphone applications Experiment Smartphone users, over 18 years old Hann et al. (2007) e-Business/e-services Experiment Students Huberman et al. (2005) Personal information trade Experiment Internet users (mean age 40) Hughes-Roberts (2013) SNSs Survey Students Lee et al. (2013) SNSs/location data Focus groups/experiment Experiment: users of SNSs (mean age 25)/ focus group: users of Location-Based Social Network Services (mean age 29) Norberg et al. (2007) Finance services Experiment Students Oomen and Leenes (2008) Internet use Survey Students Reynolds et al. (2011) SNSs Survey Facebook users Spiekermann et al. (2001) Online shopping Experiment Mainly students Taddicken (2014) SNSs Survey Users of SNSs (average age in the range of 30–39 years) Tufekci (2008) SNSs Survey Students Zafeiropoulou et al. (2013) Location data Survey Internet users (average age in the range of 26–34 years) Table 2 – Studies that provide evidence that challenge the privacy paradox hypothesis. Study Context Methodology Participants Blank et al. (2014) SNSs Survey Users of SNSs (random sample) boyd and Hargittai (2010) SNSs Survey Students Christofides et al. (2009) SNSs Survey Students D’Souza and Phelps (2009) e-Commerce Survey Students (mean age 21)/alumni (mean age 47) Egelman et al. (2012)a Smartphone applications Experiment Smartphone users, over 18 years old Lutz and Strathoff (2014) Internet use/SNSs Survey Sample of the general population (average age in the range of 30–49 years) Miltgen and Peyrat-Guillard (2014) Internet use Focus groups Internet users (average age in the range of 25–44 years) Son and Kim (2008) e-Commerce Survey Internet users (median age of 41) Tsai et al. (2011) Online shopping Survey/experiment Survey: Internet users (mean age 30)/experiment: Internet users Wakefield (2013) e-Commerce Survey Random sample (average age above 35 years) Young and Quan-Haase (2013) SNSs Survey Students a The results of this research can be interpreted in two ways, thus it appears in both the list of studies that support the privacy paradox hypothesis and those that challenge it. 126 c om pu t e r s & s e cu r i t y 6 4 ( 2 0 1 7 ) 1 2 2 – 1 3 4 3.3. Understanding the controversy Research on the privacy paradox phenomenon has produced contradictory results. Several studies have shown a dichotomy between privacy concerns and attitudes and actual privacy behaviour, whilst other studies indicate that individuals’ privacy behaviour is in line with their concerns and attitudes. In this section we investigate the causes of this contradiction and make recommendations for research to overcome the controversy. First, there is an issue of interpretation. Studies of individu- als’ valuation of privacy have provided price estimations that can be interpreted in, at least, two ways. A value of 7 Euros that users price their browsing history (Carrascal et al., 2013) can be consider too low to match the privacy concerns people express, but it also shows that people do value their privacy. We should consider, as well, that users are aware that these data are practically unprotected. We should also consider the ethical parameter. Individuals may be willing to sell, or even to give away, some personal information to a specific recipi- ent, but they still strongly object to the uncontrolled exploitation of the same data without their consent. Similarly, a premium of $1.50 for a privacy-preserving mobile application (Egelman et al., 2012) is low as an absolute value, but it can also be in- terpreted as a high valuation if we consider that it is three times the initial price of $0.49. The studies presented in Sections 3.1 and 3.2 have inves- tigated the privacy paradox in several different contexts. Most of them are concerned either with e-Commerce or SNSs. Smart- phone applications have been considered in only one study (Egelman et al., 2012) and other important online services, such as Internet telephony, remain unexplored. Privacy behaviour is a highly contextual phenomenon (Morando et al., 2014). We should not expect individuals to demon- strate the same behaviour in different contexts. Consider, for example, the studies by Norberg et al. (2007) and Tsai et al. (2011). In the first study a sample of students were first asked about their willingness to disclose specific pieces of informa- tion. Twelve weeks later a confederate visited campus under the guise of carrying out research for a pilot program for a bank. The confederate distributed data collection booklets that the students were asked to complete. Students provided signifi- cantly more information about themselves in comparison with what they stated they were willing to disclose a few weeks earlier. This study took place in the familiar environment of their classroom where students feel “protected”. Even though students were told that the market researcher was not asso- ciated with faculty, yet the influence of the environment was obviously strong. This may not diminish the validity of this re- search; nevertheless it is perilous to compare the results of this study with the results of a study of the kind Tsai et al. (2011) have conducted. The latter study involved an online shop- ping experiment where a shopping search engine displayed privacy policy information about online shops. In this very dif- ferent context, individuals were found willing to pay a premium for privacy.Thus, we may conclude that generalisation of results is unsafe and contradicting results should be expected when studies are conducted in different contexts. Personal information is not a coherent object. There are several types of personal information and people attribute different valuations to them. Data such as location, health status, browsing history, age and weight are treated differ- ently by individuals. Thus, it is not appropriate to compare studies that refer to different types of personal information. Sensitivity of information is an important moderator that is often neglected and, as Mothersbaugh et al. (2012) suggest, the privacy paradox may result from a failure to account for in- formation sensitivity. Similarly, there are several types of privacy concerns, such as concerns about social threats (including bul- lying and stalking), organisational threats (including secondary use by the data collector, secondary use by a third party, and marketing), and improper access by employers or the public (Krasnova et al., 2009). Most importantly, a variety of research methodologies can be found in privacy research. Most studies are surveys, many of them online. Surveys might be appropriate for exploring beliefs and attitudes, but they are not appropriate for studies of actual behaviour. Also, surveys are not reliable when ex- amining irregular or infrequent behaviour. Staddon et al. (2013) examined the accuracy of self-reported behaviour by compar- ing survey responses of Google+ users with their actual behaviour. They found that irregular or infrequent behaviours (e.g. changing privacy settings) are particularly difficult to report accurately. Experiments appear to be more appropriate, but again the experiment setting affects the generalisability of results (Morando et al., 2014). For example, two studies that are based on experimental auctions have produced very different results for the same type of personal information. Huberman et al. (2005) estimated that the average demand price for age was $57.56, whilst Carrascal et al. (2013) estimated the average valu- ation for age, gender, address, and salary to be 25 Euros (approx. $30).2 Both studies used the same type of auction (reverse second price auction), but the experiment setting and sample were different. In experiments it is also important to have a realistic en- vironment. Moreover, we should not expect individuals that know they are participating in an experiment to behave the same way as they would normally do. Even if they are given false information about the experiment, so as not to suspect that it is about privacy, they would not behave the same way in a laboratory or a classroom as they would at home or at work. Model structure and method of analysis are also important. Dienlin and Trepte (2015) used two different methodological approaches to test the privacy paradox, based on the same sample and survey instrument. Initially, they applied regres- sion analysis to test if privacy concerns were related to specific privacy behaviours, such as the indication of (a) authentic first name, (b) authentic last name, (c) personal address, (d) mobile phone number, (e) political or religious views, and (f) fre- quency of posts on SNSs. Regression analysis showed privacy concerns to be unrelated to the online disclosure of first and last name, the online disclosure of mobile phone number, postings of political or religious views, and the frequency of posts on SNSs. Only the disclosure of personal address was found to be related to privacy concerns. Thus, the existence privacy paradox was adequately supported. 2 Calculated according to the exchange rate at the time the study was conducted. 127c om pu t e r s & s e cu r i t y 6 4 ( 2 0 1 7 ) 1 2 2 – 1 3 4 Following an alternative methodological approach, they dif- ferentiated between informational, social, and psychological privacy and constructed a model that introduced privacy attitude and privacy intention as moderators. A Structural Equation Model- ing (SEM) analysis revealed that privacy concerns affected privacy behaviour indirectly. Specifically, they found that privacy concerns positively influence privacy attitudes, which in turn positively influence privacy intentions, which positively influ- ence privacy behaviours. Thus, when a new methodological approach was followed the privacy paradox was dissolved (Dienlin and Trepte, 2015). Thus, this research demonstrated that the use of different research models and methods of analy- sis can lead to contradictory results. 4. Interpretations of the privacy paradox and new insights Current research is focusing on interpreting the gap between privacy attitude and privacy behaviour. Interpretations of the privacy paradox are derived from five research areas: (a) privacy calculus theory, (b) social theory, (c) cognitive biases and heu- ristics in decision-making, (d) decision-making under bounded rationality and information asymmetry conditions, and (e) quantum theory homomorphism. 4.1. Privacy calculus and the benefits of self-disclosure Privacy calculus theory postulates that individuals perform a calculus between the expected loss of privacy and the potential gain of disclosure. Their final behaviour is determined by the outcome of the privacy trade-off (Dinev and Hart, 2006; Jiang et al., 2013; Xu et al., 2011). Thus, it is assumed that individu- als decide to disclose personal information when potential gains surpass expected losses. In social interactions rewards are mostly intangible and thus difficult to observe. As a result the disclosing behaviour of users often seems unreasonable and inconsistent with their privacy concerns. However, if we con- sider the intangible rewards involved, then the disclosing behaviour of users becomes more understandable. In fact, several studies have confirmed that users of SNSs weigh risks and benefits of sharing private information and disclose per- sonal information when perceived benefits outweigh observed risks (Debatin et al., 2009; Lee et al., 2013). Active participation in online social networks, which in- volves self-disclosure, is associated with three fundamental needs: (a) the need for diversion and entertainment, (b) the need for social relationships, and (c) the need for identity construc- tion (Debatin et al., 2009). Thus, for most users, satisfying the above needs overweighs the observed risks of disclosing per- sonal data. This holds even for users that have experienced privacy invasion, although these users are more likely to change their privacy settings. In addition, the use of online social net- working has been ritualised and built into users’ daily life (Debatin et al., 2009), thus, for them, it is difficult to deviate from the routine of self-disclosure. Benefits of information sharing that users value the most include self-clarification, social validation, relationship development, social control, and self-representation (Lee et al., 2013). Self-clarification refers to understanding oneself and clarifying one’s views and feelings about issues of interest. Social vali- dation is the validation of one’s views or values by other people. Relationship development is realised by enhancing the nature of significant relationships. Social control is achieved by in- fluencing others and changing their attitude or behaviour and self-representation refers to establishing an image of oneself. Social networking is a way of gaining social capital. Social capital refers to the accumulated resources derived from the relationships among people within a specific social context or network (Ellison et al., 2011). Individuals disclose personal in- formation in order to earn social capital. For example, an individual that discloses a medical diagnosis will be more likely to receive supporting messages from network members (Stutzman et al., 2012). 4.2. Social theory–based interpretations There are also strong motivations for self-disclosure stem- ming from the way online social networks have been embedded into the social lives of users, who in order to maintain their social lives, must disclose information on them despite their privacy concerns (Blank et al., 2014). Social theory may enhance our understanding of this phenomenon. Lutz and Strathoff (2014) adopt a perspective of online social networks as social collectives and make a distinction between social collectives that are held together by its members’ internalised emotional ties and implicit rules and social collectives that are held together by more rational calculations and the corresponding mechanisms, such as contracts and legal rules. The former are known in the rel- evant literature as Gemeinschaften (communities), whilst the latter are known as Gesellschaften (societies) (Tönnies, 2003). Online social networks have several characteristics that would justify their characterisation as Gemeinschaften, rules of behaviour in online social networks are mostly implicit and individuals foster their relationships and search for a feeling of belonging. In such Gemeinschaft-like forms of social collec- tives individuals are willing to provide information and data about themselves as this is an implicit part of being a member of the community (Lutz and Strathoff, 2014). On the other hand, SNSs are formal institutions, mostly private companies such as Facebook Inc., with formal rules and policies. Thus, there is both a Gemeinschaft and Gesellschaft side in SNSs. When considering privacy hazards, users may adopt the Gesellschaft perspective and make rational calculations of privacy risks, whilst when acting as part of the online com- munity they may adopt the Gemeinschaft perspective. Thus, the emotional attraction of being part of a community collides with the calculated hazards of data misuse. This collision is often resolved in favour of the Gemeinschaft perspective as the emo- tional rewards of belonging to a community, being concrete and immediate, override the abstract, calculated risks of data misuse (Lutz and Strathoff, 2014). An alternative social theory that can be used to explain the privacy paradox is structuration theory (Giddens, 1984). Structuration theory is a sociological model that has emerged in an attempt to resolve the debate between social theories that emphasise the role of human agency (i.e., individuals’ ability to act based on their free choices) and those that underline the role of the social structure. Structuration theory discards 128 c om pu t e r s & s e cu r i t y 6 4 ( 2 0 1 7 ) 1 2 2 – 1 3 4 the discretion between agency and structure and claims that these do not exist independently from one another, but they rather form two sides of the same phenomenon. According to Giddens (1984, 377) structure exists only as “memory traces” and is instantiated in action. In other words, people’s actions produce, reproduce, or alter social structure, which at the same time constraints people’s actions; this process is referred to as structuration. Zafeiropoulou et al. (2013) draw upon structuration theory to provide an explanation of the privacy paradox in the context of location data, which are produced by mobile devices and used by numerous mobile applications and SNSs. They posit that privacy decisions can be seen as part of a process of structuration, where individuals do not make information- sharing decisions as entirely free agents and are instead heavily influenced by contextual factors (e.g., social norms, trust in the mobile application) during trade-off decisions (Zafeiropoulou et al., 2013). Online privacy is a new social phenomenon that people are still struggling to understand. The social representations that would allow people to understand privacy as a concept have not emerged yet, as an empirical study by Oetzel and Gonja (2011) has shown. A social representation is a conceptual scheme that comprises values, ideas, metaphors, beliefs, and practices that are shared among the members of a commu- nity. The theory of social representation suggests that individuals understand new concepts based on established schemes, through the processes of objectification and anchoring (Oetzel and Gonja, 2011). Anchoring involves the ascribing of meaning to new phenomena by means of integrating them into existing conceptual schemes, so that they can be interpreted and com- pared to available knowledge (i.e. things already known). In the process of objectification abstract concepts become concrete through the emergence of new social representations. Since a social representation of online privacy has not been estab- lished yet, often individuals do not succeed to develop a reliable perspective on online privacy. 4.3. Cognitive biases and heuristics in privacy decision-making The privacy calculus theory is based on the assumption that individuals make privacy decisions as rational agents, in the economic sense, by means of calculating risks and benefits. However, research in behavioural economics has shown that human decision-making is affected by cognitive biases and heu- ristics (Acquisti and Grossklags, 2007). It is unlikely that privacy decisions are not affected by the same biases and heuristics. The latter include optimism bias, overconfidence, affect bias, fuzzy- boundary and benefit heuristics, and hyperbolic discounting. Optimism bias refers to the consistent tendency of indi- viduals to believe that they are less at risk of experiencing a negative event compared to others. Optimism bias has a neu- rological basis (Sharot et al., 2007), which explains why it is so pervasive. Cho et al. (2010) have tested empirically the effect of optimism bias on privacy behaviour. Relying on data from a telephone survey they found that individuals display a strong optimism bias about online privacy risks, judging themselves to be significantly less vulnerable than others to these risks. Baek et al. (2014) confirmed that individuals perceive the likelihood of personal online privacy infringement to be lower than that of other individuals (comparison targets) in a study that was based on large-scale online survey data. Compara- tive optimism (i.e., the perceived difference between personal and target risk) is more pronounced when the comparison target is younger, as people tend to believe that young people are sig- nificantly more susceptible to privacy infringements. In addition, they found that optimism regarding online privacy breach is negatively related to the adoption of privacy protective behaviours. In other words, optimism bias hinders people from protecting themselves. Moreover, individuals tend to exhibit overconfidence in their skills and knowledge. In a relevant study (Jensen et al., 2005) participants were asked if they knew about certain privacy en- hancing technologies and, then, were asked a follow-up question to probe their knowledge. Less than 25% of partici- pants who claimed to know a technology were able to answer simple questions about it. In addition, when individuals are given more control over the release and accessibility of their information (i.e., they are able to control which information will be published), they tend to reveal more personal infor- mation, exposing themselves to higher privacy risks (Brandimarte et al., 2013). Affect heuristic is one of the most established human decision-making and behaviour biases (Slovic et al., 2002). It refers to a mental shortcut that allows people to make judg- ments and decisions quickly based on their affective impressions. A consequence of the affect heuristic is that in- dividuals tend to underestimate risks associated with things they like and overestimate them when associated with things they dislike. Positive affect (e.g. enjoyment) is positively related to an individual’s intention to disclose personal information (Wakefield, 2013). Affect is expected to influence the assess- ment of risks of self-disclosure, as well as the assessment of the benefits of self-disclosure (Kehr et al., 2013, 2014). Users tend to underestimate the risks of information discloser when confronted with a user interface that elicits positive affect (Kehr et al., 2015). Sundar et al. (2013) conducted an experiment, in which they tested the effect of two heuristics, the fuzzy-boundary and the benefit heuristics, on disclosure of personal information. A group of participants were shown a video that illustrated how per- sonal information could be misused by third parties (i.e. fuzzy- boundary condition) and another group was shown a video that presented the benefits of personalisation (i.e. benefit condi- tion). Later, participants in both groups were given a questionnaire to fulfill, which included several personal ques- tions. Individuals who were primed with the fuzzy boundary heuristic were less likely to disclose personal information, whilst those who were primed with the benefit heuristic tended to disclose more information about them. Based on these results the authors suggest an explanation of the privacy paradox arguing that the self-reports of increased privacy concerns noted in surveys could be a product of systematic processing, whilst actual privacy behaviours are probably determined by heuris- tic processing. The tendency to discount future benefits, i.e. to value future benefits less than present ones, has been extensively studied by economics research. One of the most prominent models of discounting is hyperbolic discounting (Acquisti and Grossklags, 129c om pu t e r s & s e cu r i t y 6 4 ( 2 0 1 7 ) 1 2 2 – 1 3 4 2003). Hyperbolic discounting theory claims that humans dis- count the future in a time-inconsistent manner; their preferences change as they approach the time to choose among options. Hyperbolic discounting has a direct effect on privacy- related decisions. When individuals are asked about their intention to adopt a privacy-protection strategy, they calcu- late the benefits of privacy protection against the benefits of information disclosure and they may find the former to be more significant. However, when they make these calculations and express their intention to adopt a privacy-protection strat- egy, they are thinking about a decision to be taken in the future. When future comes and they have to actually make that de- cision, their preferences change, as they now discount the future benefits of privacy protection by a higher factor than they did earlier. Thus, the dichotomy between intentions and behaviour can be interpreted as an inability of individuals to predict their future decisions, as their preferences on which they base their decisions are time-inconsistent. Wilson and Valacich (2012) identified two more factors that contribute to “irrational behaviour”, benefit immediacy and risk diffusion. According to their model, when individuals perceive the benefits of disclosure to be immediate rather than delayed, they tend to perceive risks to be lower and benefits to be higher. Analogously, when risk is diffused, e.g. if personal informa- tion is expected to be collected in 1–2 years from the time consent when was given, individuals tend to perceive risks to be lower and benefits to be higher. However, the above model has not been empirically tested. 4.4. Bounded rationality, incomplete information, and information asymmetries Most people are lacking the cognitive ability to calculate privacy risks and disclosure benefits and do not have access to all nec- essary information in order to make informed judgments about the trade-offs that are involved in privacy decisions. Individu- als make privacy decision in limited time having incomplete information about risks and benefits. Moreover, as cognitive psychology has shown, they are not able to calculate all the relevant parameters (Camerer, 1998). Thus, their privacy de- cisions are constrained by incomplete information and bounded rationality (Acquisti and Grossklags, 2005), two conditions that affect decision-making in several contexts (e.g. economics, busi- ness administration, etc.). Bounded rationality refers to the cognitive limitations facing a human decision maker – limi- tations of both knowledge and computational capacity. Information asymmetries prevail in the relationship between consumers and providers in the Internet and mobile market. For example, mobile application consumers have very little knowledge of how their personal data are used. Mobile appli- cation consumers do not rely on the information provided by application vendors on the collection and use of personal data, when they decide which application to download. They con- sider information from their social group and the app store to be more important and trustworthy (Buck et al., 2014). Baek (2014) showed that the dichotomy between privacy con- cerns and behavioural intention disappears when individuals are presented with arguments either for or against the use of personal information by online businesses. Participants in Baek’s study were divided in three groups. The first group was presented with a short message promoting regulation on the collection and use of personal data, the second group was pre- sented with a message with arguments supporting the collection and use of personal data, and the third group was given no message at all. Then, all participants were asked to complete a survey questionnaire that measured privacy con- cerns and intention to disclose personal information. Concerns and intentions were positively related in the first two groups, whilst concerns and intentions were unrelated in the third group. 4.5. Quantum theory homomorphism Expanding the variety of disciplines that provide a basis for explaining the privacy paradox, Flender and Müller (2012) engage concepts from quantum theory to provide an under- standing for the privacy paradox. They consider human decision-making to be analogous to the measurement process in quantum experiments. This new perspective allows incor- porating effects like indeterminacy, i.e. the outcome of a decision making process is determined at the time the decision is made but not prior to it, in descriptions of privacy decision making. Privacy decisions are affected by the indeterminacy effect as individuals may alter their preferences indeterminately, i.e. at the time an actual decision is made. 5. Discussion and recommendations Research on the privacy paradox has followed a dialectic course. Initial studies that revealed a dichotomy between privacy at- titude and actual privacy behaviour were followed by others that showed a significant influence of privacy attitude on privacy behaviour. This debate triggered significant research that has aimed to resolve the paradox either by interpreting the phe- nomenon or by building comprehensive models that unveiled the complex nature of the phenomenon. Thus, the dichotomy between privacy attitude and behaviour should not be con- sidered a paradox anymore, since recent literature provides several logical explanations. It is, however, a complex phe- nomenon that has not been fully explained yet. Current research has shed light to various aspects of the paradox, but it is still infeasible to put the pieces of the puzzle together so as to form the “whole picture”. Table 3 summarises the various explana- tions presented at the end of Section 3 and in Section 4. Research on the privacy paradox can be categorised in terms of the theoretical background, the methodological approach, and the context in which it is examined. Researchers have turned to various disciplines in search for theories that can contribute to the conceptualisation of the phenomenon and the investi- gation of probable explanations. These include social theory, behavioural economics, psychology, and quantum theory. Several researchers have studied privacy paradox from a social theory perspective, using theories such as structuration theory (Zafeiropoulou et al., 2013), media theories (Debatin et al., 2009), communicative privacy management theory (Lee et al., 2013), gemeinschaft/gesellschaft theory (Stutzman et al., 2012), and the theory of social representation (Oetzel and Gonja, 2011). Behavioural economics have contributed the concepts of bounded rationality and incomplete information that have been used 130 c om pu t e r s & s e cu r i t y 6 4 ( 2 0 1 7 ) 1 2 2 – 1 3 4 to explain privacy decisions (Acquisti and Grossklags, 2005). Also, behavioural economics have unveiled the role of cogni- tive biases and heuristics in decision making. Several researchers have studied the privacy paradox under the per- spective of psychological/cognitive biases and heuristics (Acquisti, 2004; Acquisti and Grossklags, 2003, 2005, 2007; Baek, 2014; Baek et al., 2014; Brandimarte et al., 2013; Buck et al., 2014; Cho et al., 2010; Jensen et al., 2005; Kehr et al., 2013, 2014, 2015; Sundar et al., 2013; Wakefield, 2013; Wilson and Valacich, 2012). Finally, there is one attempt to explain the privacy paradox in terms of quantum theory concepts (Flender and Müller, 2012). Although quantum theory is obviously not a neighbouring dis- cipline, quantum theory concepts, such as indeterminacy, applied isomorphically provide an interesting conceptualisation of the phenomenon. With regard to methodology, there are mainly two ap- proaches: surveys and experiments (see Table 4). Most surveys are based on convenience samples (e.g. students), which raises an issue of validity. Surveys rely on self-reported behaviour, which often differs from actual behaviour. This issue is ad- dressed by the experimental approach. Nevertheless, most experiments in the relevant literature fail to recreate a real- istic context. The privacy paradox has been studied in various con- texts. Mainly, two types of context have been studied: social situations and transactional situations. Studies of privacy in social situations are primarily concerned with SNSs, such as Facebook and Google+ , and online chatting. Transactional situ- ations include a variety of cases, including DVD stores, mobile applications, e-shops, and finance web-sites. Table 3 – Explanations of the privacy paradox. Explanations Studies Individuals perform a privacy calculus Dinev and Hart (2006); Jiang et al. (2013); Xu et al. (2011) Perceived benefits of SNS participation (e.g. satisfying fundamental needs) outweigh observed risks Debatin et al. (2009); Lee et al. (2013) Habitual use of SNSs and integration into daily life Blank et al. (2014); Debatin et al. (2009) Individuals disclose information so as to gain social capital Ellison et al. (2011); Stutzman et al. (2012) Participating in a community (Gemeinschaften) vs. participating in a society (Gesellschaften) Lutz and Strathoff (2014) Individuals do not make information-sharing decisions as entirely free agents (Structuration Theory perspective) Zafeiropoulou et al. (2013) Privacy decisions are affected by cognitive biases and heuristics (e.g. optimism bias, overconfidence, affect bias, fuzzy-boundary and benefit heuristics, hyperbolic discounting) Acquisti and Grossklags (2003; 2007); Baek et al. (2014); Brandimarte et al. (2013); Cho et al. (2010); Jensen et al. (2005); Kehr et al. (2013; 2014); Kehr et al. (2015); Sundar et al. (2013); Wakefield (2013); Wilson and Valacich (2012) Privacy decisions are affected by bounded rationality, incomplete information and information asymmetries Acquisti and Grossklags (2005); Baek (2014); Buck et al. (2014) Individuals have not developed a reliable perspective on online privacy, since a social representation of online privacy has not been established yet Oetzel and Gonja (2011) Privacy decisions are affected by the indeterminacy effect (quantum theory perspective) Flender and Müller (2012) Methodological explanations: Inappropriate/incomplete models, missing factors, inappropriate research methods, etc. Dienlin and Trepte (2015); Morando et al. (2014); Mothersbaugh et al. (2012); Staddon et al. (2013) Table 4 – Methodological approaches.a Methodological approach Studies Survey Acquisti and Grossklags (2005); Baek et al. (2014); Barnes (2006); Blank et al. (2014); boyd and Hargittai (2010); Buck et al. (2014); Carrascal et al. (2013); Cho et al. (2010); Christofides et al. (2009); D’Souza and Phelps (2009); Debatin et al. (2009); Dienlin and Trepte 2015); Ellison et al. (2011); Hughes-Roberts (2013); Jiang et al. (2013); Krasnova et al. (2009); Lutz and Strathoff (2014); Son and Kim (2008); Oomen and Leenes (2008); Reynolds et al. (2011); Stutzman et al. (2012); Taddicken (2014); Tufekci (2008); Wakefield (2013); Young and Quan-Haase (2013); Zafeiropoulou et al. (2013) In-depth interviews/focus groups Brown (2001); Debatin et al. (2009); Ellison et al. (2011); Lee et al. (2013); Miltgen and Peyrat-Guillard (2014); Young and Quan-Haase (2013) Analysis of (actual) data Hughes-Roberts (2013); Reynolds et al. (2011); Staddon et al. (2013) Experiment Baek (2014); Beresford et al. (2012); Brandimarte et al. (2013); Egelman et al. (2012); Hann et al. (2007); Huberman et al. (2005); Jensen et al. (2005); Kehr et al. (2014; 2015); Lee et al. (2013); Mothersbaugh et al. (2012); Norberg et al. (2007); Spiekermann et al. (2001); Sundar et al. (2013); Tsai et al. (2011); Xu et al. (2011) Conceptual/analytic Acquisti (2004); Acquisti and Grossklags (2003; 2007); Barnes (2006); Flender and Müller (2012); Kehr et al. (2013); Oetzel and Gonja (2011); Son and Kim (2008); Wilson and Valacich (2012) a Studies that appear in more than one category use a combination of methods. 131c om pu t e r s & s e cu r i t y 6 4 ( 2 0 1 7 ) 1 2 2 – 1 3 4 5.1. Recommendations The studies presented in this paper refer to several different types of personal information. The latter include age, weight, phone number, address, date of birth, income, photos, brows- ing history, location data, SNS posts, religious and political beliefs, etc. Personal information is not homogeneous and in- dividuals’ attitudes vary depending on the type of personal information concerned. Moreover, different types of privacy con- cerns are considered, such as social threats (e.g., bullying and stalking), organisational threats (e.g. secondary use), and im- proper access by employers or the public. It should be expected that some types of privacy concerns have a stronger influ- ence on attitudes and behaviour than others. Since most of the above studies focus on individual aspects of the privacy paradox phenomenon, there is a need for syn- thetic studies that would be based on comprehensive theoretical models that take into account the diversity of personal infor- mation, as well as the diversity of privacy concerns. Studies of this kind would allow us to build a clearer picture of the re- lation between privacy attitudes and behaviour. Also, current research has not considered the diversity of privacy harms (Solove, 2006). This is an important variable that should be further investigated. Regarding the research methodology, both surveys and ex- periments are useful research instruments. Nevertheless, future research should address the shortcomings of these methods that we have witnessed in previous research. Survey re- search should take into account the fact that self-reports on privacy behaviour are unreliable, especially when they refer to infrequent events (e.g. adjusting privacy settings in SNSs).There- fore, future research should make more use of “hard data”, i.e. evidence of actual behaviour, rather than self-reports. Surveys should also consider that the privacy paradox is not a symptom of young people, but it concerns users of all ages. Therefore, samples should be as representative as possible. Future research could also focus on specific age and cultural groups, such as elderly individuals, rural cultural groups, etc. Both survey and experimental research should take into account the fact that privacy is a highly contextual phenom- enon. Particularly experiments should be conducted in realistic settings that provide a rich and relevant context. Compara- tive studies could also examine privacy attitudes and behaviour in different contexts, such as online shopping, SNSs and e-government services. With regard to background theories although the privacy paradox has been studied through a variety of theoretical lenses, no theoretical model has prevailed, thus there is still room for new theoretical perspectives. In particular, there are several behavioural science theories that could be consid- ered, such as social cognitive theory and its derivatives (Bandura, 2001). Finally, we may notice that the privacy paradox has been studied in isolation. The relation of privacy behaviour with privacy awareness campaigns, with the technological envi- ronment and the availability of privacy enhancing technologies, has been under-researched. Moreover, a better understand- ing of the privacy paradox may enable a new perspective on the legal and ethical framework of information privacy. Con- cluding, we may argue that although there has been a large volume of research on the privacy paradox, it remains a wide open issue. "
1," The Personalization Privacy Paradox: An Empirical  Evaluation of Information Transparency and the  Willingness to be Profiled Online for  Personalization1  By: Naveen Farag Awad  Wayne State University  Detroit, Ml 48202  U.S.A.  nawad@wayne.edu  M. S. Krishnan  Business Information Technology  University of Michigan Business School  Ann Arbor, Ml 48109  U.S.A.  mskrish@umich.edu  Abstract  Firms today use information about customers to improve service and  design personalized offerings. To do this successfully, however,  firms must collect consumer information. This study enhances  awareness about a central paradox for firms investing in personali  zation; namely, that consumers who value information transparency  are also less likely to participate in personalization. We examine  the relationship between information technology features, speci  fically information transparency features, and consumer willingness  to share information for online personalization. Based on a survey  !V. Sambamurthy was the accepting senior editor for this paper. Prabhudev  Konana was the associate editor. Sridhar Balasubramanian and Nirup Menon  served as reviewers.  of over 400 online consumers, we examine the question of whether  customer perceived information transparency is associated with  consumer willingness to be profiled online. Our results indicate that  customers who desire greater information transparency are less  willing to be profiled. This result poses a dilemma for firms, as the  consumers that value information transparency features most are  also the consumers who are less willing to be profiled online. In  order to manage this dilemma, we suggest that firms adopt a  strategy of providing features that address the needs of consumers  who are more willing to partake in personalization, therefore  accepting that the privacy sensitive minority of consumers are  unwilling to participate in personalization, despite additional  privacy features.  Keywords: Online privacy, information transparency, Web site  features, online experience, consumer privacy, online personali  zation, online information sharing, empirical studies of information  systems, business value of information systems, information sharing  practices.  Introduction IHHHHHBHH1HHBHH  The ability to collect, analyze, and respond to user information is of  growing importance. To survive, companies depend on vast  quantities of information to build rapport with existing customers  and attract new business (Culnan and Armstrong 1999). As the ease  and availability of e-business reduces face-to- face interaction, firms  must use consumer information to attempt to offer personalized  service that will increase value and consequently, consumer loyalty.  As Weill and Vitale (2001, pp, 24-25) state,  MIS Quarterly Vol. 30 No. 1, pp. 13-28/March 2006 13 This content downloaded from  �������������87.63.109.206 on Wed, 17 Jun 2020 11:09:38 UTC�������������  All use subject to https://about.jstor.org/terms  Awad & Krishnan/Personalization Privacy Paradox  Information technology (IT) infrastructure and the  information it contains, particularly customer information,  will be a critical success factor for all e-business  initiatives, thus raising the stakes for the management of  the firm's IT investments and assets.  However, implicit in the collection of consumer information is a  concern for consumer privacy. Information privacy is one of the  most important issues facing management practice (Mason 1986;  Safire 2002); if managers are not careful, their firms may be the  victims of consumer backlash for overstepping the bounds of  expected information practices.  The objective of this paper is to examine the relationship between  information transparency and consumer willingness to partake in  personalization. Specifically, we examine two research questions.  Do information transparency features, which provide knowledge of  information and procedures, affect consumer willingness to be  profiled online for personalized offerings? Does the effect of infor  mation transparency features on a consumer's willingness to be  profiled online differ across personalized service versus personalized  advertising? This paper uses a utility maximization theory frame  work to examine these questions. The major contribution of this  research is that it provides empirical evidence of a central paradox  for firms investing in personalization.  In the next section, we review and discuss prior literature. We then  discuss the theoretical model and hypotheses of this paper. In the  fourth section, we explain the data and measurement. The analysis  and results are presented, followed by a discussion of the results and  their managerial implications. We conclude the paper with direc  tions for future research.  Prior Literature M_________________l  Public opinion surveys show that citizens are quite concerned about  threats to their information privacy (Equifax 1996; Harris and  Westin 1998; Westin 1997). Several of the expressed privacy  concerns centered on the process firms utilize to collect and use  personal data. Other studies have examined the likelihood  consumers will partake in online personalization services from a  purely consumer-characteristics standpoint. For example, Chellappa  and Sin (2005) examine consumer attributes such as privacy concern  and personalization value; they also examine how such attributes  affect consumer likelihood of using personalization services. While  we also include consumer attributes, the main focus of our study is  the consumer-rated importance of perceived information  transparency. By information transparency features we mean  features that give consumers access to the information a firm has  collected about them, and how that information is going to be used.  Table 1 summarizes various examinations of the issue of  information collection and information privacy. The table includes  the constructs used in each paper, the setting (offline or online), as  well as the theoretical foundations and main findings.  The information privacy research outlined in Table 1 is grounded in  the basic definition of privacy found in psychology literature.  Privacy is defined as ""the ability of the individual to control the  terms under which personal information is acquired and used""  (Westin 1967, p. 7). Information privacy, then, refers to ""the ability  of the individual to personally control information about one's self  (Stone et al. 1983, p. 461). Hence, it may be interpreted from this  definition that one way to decrease the level of perceived privacy  risk for the online consumer is to increase his or her level of control  over personal information. Previous research has suggested that  issues of informational control are essential in creating a favorable  consumer predisposition toward contributing information to online  firms (Stewart and Segars 2002).  Knowledge has been shown to be a determinant of perceived control  (Armitage and Conner 1999; Azjen and Driver 1991; Wormian  1975). We extend this idea of knowledge as a control mechanism  to improving consumer comfort online, since previous research  shows that adult Internet usage may be constrained by the perceived  need for additional knowledge and better understanding of the  medium (Klobas and Clyde 2000).  In this paper, we use a utility maximization framework to examine  control, as implemented through IT-enabled information trans  parency. The main construct of interest in this paper is a consumer's  rated importance of information transparency features that online  firms can provide. These features have a different meaning in the  offline setting than in the online setting. In the offline setting, there  is no clear way to visually access a consumer's personal data when  dealing with, for instance, a catalog marketer. Thus, such a func  tional distinction in the online setting versus the offline setting  demands that the online context be studied separately. The  contributions of this paper to the literature are  (1) While the bulk of previous research has examined willingness  to share information in the offline setting, this paper adds to our  understanding of willingness to be profiled for personalization  in the online context.  (2) This paper examines a new construct: the importance of  information transparency features (such as data transparency,  data removal, and time expirations of data) towards increasing  consumer willingness to be profiled online.  (3) This paper explicitly contrasts two varying outcomes, adver  tising and service, in order to assess if a difference in outcome  utility affects the willingness to share information.  (4) While prior studies have examined the likelihood of consumers  partaking in online personalization from a purely consumer  characteristic standpoint (e.g., Chellappa and Sin 2005), this  paper studies both consumer characteristics and past consumer  experiences in the context of privacy concerns, and their  association with willingness to be profiled online.  14 MIS Quarterly Vol. 30 No. 1/March 2006 This content downloaded from  �������������87.63.109.206 on Wed, 17 Jun 2020 11:09:38 UTC�������������  All use subject to https://about.jstor.org/terms  Awad & Krishnan/Personalization Privacy Paradox  Table 1. Previous Information Privacy Literature  Context Underlying  Authors and (Offline/ Theoretical  Year Research Questions Online) Constructs Used Framework Main Findings  Laufer et al. What are some of the Offline Concern about immediate Environmental Perceived control over  (1976) of privacy? What event psychology various uses of information  factors affect Concern about future events results in less consumer  consumer concern Control over information concern over privacy  over privacy usage invasions.  _invasions?_* Consumer privacy concern_  Stone et al. How do values, Offline Information privacy values Applied The more a user values  (1983) beliefs, and attitudes Information privacy beliefs psychology privacy, or rather, the more  towards information Information privacy attitudes concerned about privacy,  privacy vary across Types of organizations the less control the  organizational types? consumer perceives to have  _over personal information.  Stone and How does information Offline Type of personality inventory Expectancy Organizations that do not  Stone (1990) acquisition affect Purpose of information theory of consider the rights of  physical/ social request for information on motivation individuals may experience  structure in a work individuals' reactions to lower job acceptance rates,  environment? personality inventories higher turnover, sabotage,  Information flows and increased litigation.  Individual information rights  Physical structure of work  environment  Social structure of work  environment  Job acceptance rate  _ Job turnover_  Goodwin What are the ele- Offline Environmental control Control as central Consumer privacy is  (1991) ments of the right of Social use of information aspect of privacy; defined based on two  consumer information control social psychology dimensions of control:  privacy? control of information dis  closure, and control over  unwanted intrusions into the  _consumer environment.  Culnan (1993) What factors affect Offline Attitude toward secondary No general theory Control differentiates parti  consumer attitudes information use of secondary cipants' attitude toward  toward secondary Concern for privacy information use secondary information  information use? Attitudes toward direct mail applied usage. Study participants  marketing with positive attitude are  Demographics less concerned about pri  vacy, perceive shopping by  mail as beneficial, and have  coping strategies for  _unwanted mail._  Smith (1994) How should corpor- Offline The right of individuals and Strategic Developed a model to  ations manage infor- groups to decide when, explain corporate  mation privacy where, and how information approaches to information  policies? about themselves is to be privacy policy-making.  _used_  McKnight et Why is initial trust Offline Disposition to trust Cognitive Initial trust levels are based  al. (1998) level high? Institution-based trust approach on specified conditions  Cognitive processes related to antecedents of  Trusting beliefs trusting intention.  _* Trusting intentions_  MIS Quarterly Vol. 30 No. 1/March 2006 15 This content downloaded from  �������������87.63.109.206 on Wed, 17 Jun 2020 11:09:38 UTC�������������  All use subject to https://about.jstor.org/terms  Awad & Krishnan/Personalization Privacy Paradox  Table 1. Previous Information Privacy Literature (Continued)  Context Underlying  Authors and (Offline/ Theoretical  Year_Research Questions Online)_Constructs Used_Framework_Main Findings_  Culnan and Can organizations Offline Willingness to have personal Privacy calculus; When fair information prac  Armstrong address privacy con- information used with fair social contract tices are used, privacy con  (1999) cerns through proce- information practices theory cerns do not affect  dural fairness? Willingness to have personal willingness to be profiled.  information used without fair  information practices  Privacy  Direct marketing experience  _frequency_  Hoffman et al. How are consumer Online Relationship termination Consumers Recognizing consumers'  (1999) concerns affecting the costs structure their rights to data ownership on  growth and develop- Relationship benefits decisions in the the Internet is the first step,  ment of online com- Shared values context of a Industry acceptance and  mercial activity? Communication relationship enforcement of stated opt  What are the Opportunistic behavior development out policies regarding  implications of these Five outcomes process; Morgan information exchange is  concerns for one 'Acquiescence and Hunt's (1994) necessary. Ultimately, opt  potential industry Propensity to leave key mediating in, informed consent  response: the Cooperation variable model, policies are likely to reap  commercial uses of Functional conflict based on rela- the greatest rewards for  online anonymity? Decision-making uncertainty tionship commit- online firms.  _ment and trust_  Milburg et al. What is the link Offline Corporate management of Theories of A country's regulatory  (2000) between corporate personal data cultural values approach to information  privacy management Regulatory approaches to and governance; privacy is affected by  practices and information privacy multidimensional cultural values and  individuals concern Consumer reactions across theories of individuals information  over privacy and cultures privacy privacy concerns,  government  _regulation?_  Milne (2000) Can improving Online and Information requests and Information Improving information  exchange mechanism Offline disclosure statements exchange exchange will better inform  provide consumers Information provision and framework consumers of the trade-offs  more control? marketing contact of personal information  Information capturing dissemination,  without consent  _* Information practices_  Milne and What factors affect Online and Consumer awareness of Consumer control Name removal preferences  Rohm (2000) consumer name Offline data and awareness vary by channel, consumer  removal preferences? Knowledge of name removal as basis of con- privacy state, channel  Are the existing mechanisms sumer privacy specific purchase  mechanisms for Willingness to remove experience, and consumer  providing consumer personal information from demographics,  control adequate? direct response  Preferences for controlling  personal information across  _channels_  Phelps et al. What is the relation- Offline Type of personal information Social contract Publicizing data  (2000) ship among cate- requested theory management practices can  gories of personal Amount of informational help address consumer  information, beliefs control offered privacy concerns.  about direct mar- Potential consequences and  keting, situational benefits of exchange  characteristics, speci- Consumer characteristics  fie privacy concerns,  and consumers' direct  _marketing habits?_  16 MIS Quarterly Vol. 30 No. 1/March 2006 This content downloaded from  �������������87.63.109.206 on Wed, 17 Jun 2020 11:09:38 UTC�������������  All use subject to https://about.jstor.org/terms  Awad & Krishnan/Personalization Privacy Paradox  Table 1. Previous Information Privacy Literature (Continued)  Context Underlying  Authors and (Offline/ Theoretical  Year_Research Questions Online)_Constructs Used_Framework_Main Findings_  Andrade et al. Which of three Online Completeness of the privacy Social exchange Completeness of the  (2002) approaches are policy theory privacy policy and  successful in Reputation of the company reputation of the company  encouraging self- Offer of a reward reduce the level of concern  disclosure? over self-disclosure, while  the offer of a reward  _heightens concerns._  Barwise and How effective is Online Type of advertisement Elements of Consumers respond well to  Strong (2002) permission-based Relevance permission-based text ads that grab attention  mobile advertising Frequency marketing and are relevant. Explicit  and for which Standard of copy permission is essential,  contexts is it well Reward  _suited?_* Explicit permission_  Chellappa and How do consumer Online Personalization Service quality Personalization and privacy  Sin (2005) dispositions affect Privacy measurement are independent constructs,  consumer likelihood Trust Personalization value  of using person- Intent to use personalization outweighs privacy concern  alization services? services in intention to use  _personalization_  Dinev and What are the ante- Online Perceptions of vulnerability Privacy calculus Perceived vulnerability,  Hart (2002) cedents to privacy Trust trust, and personal interest  concerns of Internet Personal interest are antecedents to privacy  users? Ability to control concerns.  _* Privacy concerns_  Schoenbachle Which factors are Offline Trust in the organization Trust as a driver The consumer-firm  r and Gordon important in building Perceived risk of database relationship is dependent  (2002) trust in an organiza- Credibility driven marketing upon trust, which may be  tion? What role does Past experience with more dependent upon a  trust play in building company company's reputation and  organizational Reputation of company dependability than on the  relationships? Perception of dependability purchase situation.  Willingness to provide  information  Perception of relationship  _with company_  Tezinde et al. What makes pe- Online Affiliation Exploratory study Personalization, brand  (2002) rmission marketing Personalization and in permission equity, and previous  effective in in- customization marketing relationships influence  fluencing consumer Customer response rate deployment marketing response rates.  interest and  behavior?  Theoretical Model  and Hypotheses  Consumer willingness to share information online involves  evaluating the outcome of online profiling. Hence, consumers must  determine the degree to which they will allow online profiling. A  classic framework used to understand this consumer decision, from  an economic perspective, is utility maximization theory. Utility  maximization has been applied to consumer privacy in previous  research to examine the market for privacy (Rust et al. 2002). How  ever, other online privacy researchers have pointed out the short  comings of utility maximization theory. For example, the theory  postulates the consumer's goal of maximizing personal economic  utility; however, consumers tend not to make a financial cost-benefit  analysis of social contracts with unpredictable outcomes (Hoffman  et al. 2002). This classic criticism dates back to 1964 when Blau  (1964) suggested that utility maximization was difficult to apply to  social exchanges because there is no precise value to social  exchange. Another problem involves the lack of a clear distinction  between the values of one social exchange from another.  MIS Quarterly Vol. 30 No. 1/March 2006 17 This content downloaded from  �������������87.63.109.206 on Wed, 17 Jun 2020 11:09:38 UTC�������������  All use subject to https://about.jstor.org/terms  Awad & Krishnan/Personalization Privacy Paradox  Gender l l  -^s+ Willing to be  Education V^N profiled online  1 Income ^^t^^X_-^^-""-""""~-~^l_ for Personalized  '-^^-H ^^ ^ Service  1 Previous Online K+ jE Importance of _-_^ -  Privacy Invasion ^* Information Willing to be  I-?-1 + ^""OH Transparency | profiled online  [Privacy Concern 1<S""-=-* ^ Personalized I I t^ Advertising  I Importance of |___:_^ -  1 Privacy Policies 1 |_|  Figure 1. Research Model  Despite acknowledged theoretical weaknesses, previous research  suggests that while consumers do not compute an exact cost-benefit  analysis for each information exchange, they do weigh the involved  tradeoff. This tradeoff has been directly studied offline as the  privacy calculus, which measures the usage of personal information  against the potential negative consequences of disseminating  personal information (Laufer and Wolfe 1977; Milne and Gordon  1993; Stone and Stone 1990). Our study examines this specific  trade-off that consumers make in the online setting as we draw upon  utility maximization theory to examine this apparent tradeoff.  The consumer's utility function is the following:  U(X) = Benefit -Cost (1)  where Benefit is derived through the degree of personalization  received and Cost is a function of consumer privacy concerns,  previous privacy invasion experience, and consumer-rated impor  tance of information transparency and privacy policies. Thus, we  propose an implicit cost function as follows:  Cost = / (consumer privacy concern, previous privacy  invasion, consumer-rated importance of information  transparency, consumer-rated importance of privacy  policies) (2)  We control for consumer demographics, including income,  education, and gender, when testing this model as it is likely that the  effects positing in the model may vary with certain demographic  variables. Thus, overall the net utility is based on the individual  elements of the cost function.  This study focuses on whether information transparency features  have an effect on consumer willingness to be profiled online. The  overall research model for this paper is illustrated in Figure 1.  Hypotheses ^ l  Information Transparency  We examine the value of information transparency to consumers in  two stages. First, we examine the degree to which consumer  demographics, as well as the experience of previous online privacy  invasions, shapes consumer-rated importance of information  transparency. In the second stage, we examine the aforementioned  effect of information transparency on consumer willingness to  partake in online profiling. For the first stage, we expect consumer  privacy concern and previous privacy invasions to be associated  with a greater value of data transparency and control, and therefore  a higher consumer-perceived value of information transparency.  Thus, we hypothesize that consumer privacy concern and previous  privacy invasions are associated with an increase in consumer-rated  importance of information transparency.  Hypothesis la: Consumer-rated importance of informa  tion transparency increases with increased general con  sumer privacy concern level.  Hypothesis lb: Consumer-rated importance of informa  tion transparency increases with consumers whom have  previously had their privacy invaded online.  Westin (1991) found that a portion of the consumer population can  be classified as privacy fundamentalists. These privacy fundamen  talists are extremely concerned about any use of their data and  generally unwilling to provide their data to Web sites, even when  privacy protection measures were in place. Cranor et al. (1999)  found that privacy fundamentalists were twice as likely as other  consumers to report having been a victim of an invasion of privacy  on the Internet, and were also less willing to answer a survey  question about their household income. It is our expectation that  18 MIS Quarterly Vol. 30 No. 1/March 2006 This content downloaded from  �������������87.63.109.206 on Wed, 17 Jun 2020 11:09:38 UTC�������������  All use subject to https://about.jstor.org/terms  Awad & Krishnan/Personalization Privacy Paradox  these privacy fundamentalists have a high value for information  transparency features, and simultaneously rate their willingness to  partake in online personalization as very low. Thus, we hypothesize  that consumers who rate the importance of information transparency  features higher are more wary of sharing personal information, and  will be less willing to participate in online personalization.  Hypothesis 2: Consumers who rate information trans  parency as important are more wary of sharing personal  information and therefore less willing to participate in  online profiling.  Privacy Policy  Firms attempt to address consumer concerns regarding online  profiling by posting their privacy policy online. Privacy policies are  written statements, usually posted on a firm's Web site and  presented during user registration, which explain information  practices regarding the collection and usage of information. While  a privacy policy is an aggregated written statement of the  information practices, information transparency allows consumers  to access their data as well as the firm's use of such data. Since we  are focusing on the consumer perspective in this paper, privacy  policies and information transparency features are not substitutes.  Prior literature has shown that consumers who express concern over  their own privacy perceive little control over the use of their  personal information (Stone et al. 1983). It follows that consumers  who value the privacy policies of firms are likely more concerned  about information transparency features as well.  We examine the degree to which consumer-rated importance of  privacy policy is associated with consumer-rated importance of  information transparency features. We expect that consumers who  value the aggregate view presented in the privacy policy will also be  more likely to value more specific details about the information and  usage practices of the firm, accessed through information trans  parency features. We hypothesize the correlation in the direction of  general to more specific, where privacy policies provide an overall  view, and information transparency features provide more specific  information. Thus, we hypothesize that consumer-rated importance  of a privacy policy will be associated with the rated importance of  information transparency.  Hypothesis 3: Consumer-rated importance of information  transparency increases with increased consumer-rated  importance of the existence of a firm's privacy policy.  In the second stage of our model, we examine the importance of a  privacy policy on consumer willingness to partake in online  profiling. Consumers who value firm privacy policies are likely  more wary of sharing their personal information with firms than  consumers who do not. Thus, increased consumer-rated importance  of privacy policies is likely associated with a decrease in consumer  willingness to participate in online profiling.  Hypothesis 4: Consumers who rate the existence of a  firm's privacy policy as important, are more wary of  sharing their information online, and are therefore less  willing to partake in online profiling.  Consumer Privacy Concern  Consumer concerns are affecting Internet commerce. A 1997 study  revealed that purchases via the Internet would receive a $6 billion  boost by the year 2000 if consumers believed their privacy wasn't  at stake during such transactions (Greene 1997). From a theoretical  standpoint, personal values, such as privacy concerns, affect the  value a consumer associates with the outcome of personalization.  Consumers with a higher level of privacy concern will likely  perceive personalization offerings to be of less value than consumers  with a lower level of privacy concern. We test this finding that users  who express concern over their own privacy are likely less willing  to share such information (Stone et al. 1983) in the online setting  and, specifically, in accordance with utility maximization theory.  Thus, we hypothesize that greater privacy concern is associated with  less willingness to be profiled online.  Hypothesis 5: Consumer willingness to partake in online  profiling decreases with a higher level of general privacy  concern.  Previous Privacy Invasion  Personal experiences guide behavior in activities that can be  subjectively deemed as privacy-related (Bates 1964). In addition,  personal experiences cause a change in privacy concern over an  individual's lifetime (Harris 1991). In this paper, we examine  previous privacy invasion experience. Online privacy invasion can  range from unsolicited e-mail spam to identity theft. Consumers  who have previously had their privacy invaded may not place much  value on the expected outcome of useful personalization. This  decreased value of personalization may result in a decreased willing  ness to partake in online profiling.  The role of past experience has been previously analyzed offline in  two different formats, with mixed results. In one instance, con  sumers were asked if they had ""experienced a previous invasion of  privacy"" (Culnan 1993). In a second instance, consumers were  asked if they had previously dealt with the firm. In the first  instance, prior privacy invasion experience was not shown to have  a clear association with attitudes toward secondary information use  offline. However, previous privacy invasion experience could affect  an individual's concern for privacy (Culnan 1993). In the second  instance, prior firm experience distinguished those willing to store  information in a customer profile and those who were unwilling to  do so offline (Culnan and Armstrong 1999). In our research, we  look at the former, prior privacy invasion experience, where  previous results have not been conclusive. Previous research did not  MIS Quarterly Vol. 30 No. 1/March 2006 19 This content downloaded from  �������������87.63.109.206 on Wed, 17 Jun 2020 11:09:38 UTC�������������  All use subject to https://about.jstor.org/terms  Awad & Krishnan/Personalization Privacy Paradox  find a significant association between previous privacy invasion  experience and attitude toward secondary information use (Culnan  and Armstrong 1999). However, we are attempting to assess the  effect of previous privacy invasion experience in an online context,  rather than the direct mail context. Therefore, we expect previous  online privacy invasion experience to have a significant effect on the  willingness to partake in online personalization. Thus, we  hypothesize that previous privacy invasions are associated with a  decreased consumer willingness to be profiled online.  Hypothesis 6: Consumer willingness to partake in online  profiling decreases with those consumers who have  previously had their privacy invaded.  Personalized Service and  Personalized Advertising  Previous research has shown that firms can improve the perceived  value of services offered by mitigating a customer's perceived risk  (Heskett et al. 1990). The perceived benefit of an outcome, such as  useful personalization, can motivate consumers to partake in online  profiling despite privacy concerns. On the other hand, the perceived  risk associated with an outcome can decrease the willingness to  partake in online personalization. In this study, we examine two  separate contexts with potentially two levels of benefit:  personalized advertising and personalized service. We expect  consumers to place different values on the two outcome contexts due  to varying levels of perceived benefit from the activities. Such a  difference in each outcome's utility value to the consumer should,  therefore, affect consumer willingness to share information. Note  that while the costs associated with the consumer decision remain  the same, the benefit is different. Through examining two service  types of personalization, we aim to test how differing utilities, and  consequently different benefits, are associated with a consumer's  decision to partake in online personalization.  Research Methodology HHBHIM  The context for this research is the use of personal information  gathered through Web sites and user willingness to allow online  collection and use of personal information by firms. The study is  based on a fresh analysis of data from a survey conducted at a large  Internet service provider during the summer and fall of 1998. The  survey focuses on issues of personal information collection through  specific online scenarios as well as general attitudes and user  demographics. The survey was designed to focus on the way people  respond to situations when personal information is collected online.  In a pre-study, variance across participants in information sharing  habits was best revealed through questions based on specific online  scenarios (Cranor et al. 1999). Thus, specific purchasing scenarios,  focusing on information goods and financial services, were utilized.  The survey also aimed at determining participants' general attitudes  and demographics. Attitude and demographic questions were taken  from other studies, such as Westin (1997). For all constructs of this  study, explicit questions were used as a mechanism for deriving  information from the participants.  The survey was developed and pretested on nontechnical employees  and summer students of the service provider, as well as with two  classes at Harvard and Massachusetts Institute of Technology.  Prospective survey participants were selected from the Digital  Research, Inc. (DRI) Family Panel. The DRI Family Panel is a  group of random Internet users that participate in product  evaluations and survey responses for Family PC magazine.  Approximately one-third of the panel members are Family PC  subscribers; most of the panel members who are not subscribers  joined the panel after visiting the Family PC Web site. Invitations  to complete the Web-based survey were e-mailed to 1,500 Family  Panel members (selected randomly). This request resulted in 523  completed surveys in November of 1998?a response rate of 35  percent. Code numbers were used to ensure that each respondent  completed only one survey; a sweepstakes was also offered as an  incentive to participate.  Similar to recent work on information privacy (Harris and Westin  1998; Stewart and Segars 2002), the sample differed from a  nationally representative sample in education, Internet usage, and  household income. All three of these categories were higher than  the national average. Having a more educated population that is  familiar with the Internet may imply that the overall sample is  actually less worried about information misuse on the Internet than  a national sample (Klobas and Clyde 2000). However, the  population is also wealthier than the national average, which may  indicate that they have more to lose financially should they  experience identity theft. Summary demographic information is  shown in Table 2.  All items selected for use in this study were chosen from a larger,  more general questionnaire. Most of the items used were single  questionnaire items. For example, a single item?whether a person  would be willing to participate in online profiling for online  personalized service?was used to measure a consumer's willing  ness to be profiled for personalized service. We note this as a  limitation of our study and suggest that future research could  confirm the findings of this study with multi-item constructs. The  item selection was based on the attitude the construct was attempting  to assess. There were two constructs where multiple items were  selected, namely privacy concern and information transparency.  The items that comprised these constructs were factor analyzed, as  explained below.  Construct Operationalization  The existing literature was examined to identify appropriate factors  for consumers deciding to share their information online. In  addition, exploratory interviews with online consumers were con  ducted. The consumers confirmed that the factors being examined  20 MIS Quarterly Vol. 30 No. 1/March 2006 This content downloaded from  �������������87.63.109.206 on Wed, 17 Jun 2020 11:09:38 UTC�������������  All use subject to https://about.jstor.org/terms  Awad & Krishnan/Personalization Privacy Paradox  Table 2. Demographics  Variable Yes No  Use computer at home 375 (98.4%) 2 (.5%)  Use computer at work 260 (68.2%) 119 (31.2 %)  Send or receive e-mail 379 (99.5%) 2 (.5%)  Visit Web sites 379 (99.5%) 2 (.5%)  Are you male or female? Male: 183 (48.0%) Female: 195 (51.2%)  Variable Mean Standard Deviation  What is the highest level of school completed? (1 3.58 0.96  = less than high school;  5 = postgraduate)  Total 1997 household income 4.33 1.37  (1 = $15,000 or less; 6 = $75,000 or more)  How many people live in your household 3.31 1.31  How many children ages 8 to 12 live in your 0.50 0.99  household?_  did capture elements of the decision to share information online.  Through this process, a set of 13 items, representing 4 different  consumer decision factors, were selected. A total sample of 401  consumer responses was examined.  Confirmatory factor analysis was used to verify that our operational  items captured the specific dimensions of the tradeoffs involved in  consumer information sharing online. The three measurement  properties considered minimally important for demonstrating  validity of operational items are unidimensionality, construct  reliability, and discriminant validity (Bagozzi 1980). The initial  model structure had poor model fit. Thus, items with low loadings  (less than 0.50) (Rivard and Huff 1988) were removed from the  model. The final 10-item model, comprising 6 factors affecting  consumers' decision to share information online, is shown in  Table 3. The indices of model fit illustrate the unidimensional  validity of the items. All of the individual item loadings are high  and significant. While the root mean squared error of approximation  (RMSEA) should ideally be less than 0.05, a RMSEA that is less  than 0.08 is practical evidence of good model fit (Browne and  Cudeck 1993, p. 144). We acknowledge that our model fit is on the  margin, as the RMSEA is 0.08, and we therefore examine other fit  indices as well. The probability value for the model's chi-square  statistic should not exceed a standard cutoff of 0.05 (Bentler 1989,  p. 37). In addition, another fit index that is commonly used is the  goodness of fit index (GFI); values greater than 0.90 are considered  good model fit (Bentler 1989).  Reliability of the factors exceeded the accepted threshold of 0.70  (Nunally 1967). The reliability of each factor was 0.87 for privacy  concern and 0.75 for information transparency.  Variable Definitions  Consumer willingness to be profiled: To measure consumer  willingness to be profiled for personalized service and personalized  advertising, two dependent variables were used. These variables,  measured via a five-point Likert sale, are (1) consumer willingness  to be profiled by a familiar site for personalized service (PSERV)  and (2) consumer willingness to be profiled by a familiar site for  personalized advertising (PADV). (All instrument question details  can be found in Appendix A.)  Information transparency: Knowledge is a core element of  perceived control. The link between knowledge and control has  been studied in other information systems contexts, such as systems  development (Kirsch 1996). Thus, one would expect that consumers  who desire greater information transparency are really striving for  greater control. We use the information transparency variable to  measure consumer-rated importance of information transparency  features. The information transparency variable was measured using  four 3-point Likert-scaled items. All four items loaded unam  biguously on a single factor and were combined to form the  information transparency (INFOTRANS) construct (Cronbach's  alpha = 0.75). The items in the information transparency construct  include (1) consumer-rated importance of whether a company gives  consumers access to what information they keep about the consumer  in their database, (2) consumer-rated importance of whether a site  allows the consumer to determine the length of time that collected  information will be retained, (3) consumer-rated importance of  whether the site shows the consumer the purpose for which the site  collects the information, and (4) consumer-rated importance of  whether a site plans to use collected information in a manner that  will identify the consumer.  MIS Quarterly Vol. 30 No. 1/March 2006 21 This content downloaded from  �������������87.63.109.206 on Wed, 17 Jun 2020 11:09:38 UTC�������������  All use subject to https://about.jstor.org/terms  Awad & Krishnan/Personalization Privacy Paradox  Table 3. Factors That Affect Consumers' Decision to Share Information Online  Standardized  Construct and Items Parameter Estimate t-value  Information transparency  Importance of whether a site is going to use the information they collect from me 0.69613 10.961  in a way that will identify me  Importance of know how long a company will retain information they collect from 0.69240 13.034  me in their database  Importance of knowing what information a company keeps about me in their 0.62952 11.695  databases  Importance of why, for what purpose, the company is collecting info from me 0.54051 11.054  Privacy concern  Concern about threats to your personal privacy in America today 0.83740 13.013  Concern about threats to your personal privacy today when using the Internet 0.82671 2.157  Notes: Model fit indices:  Goodness of fit (x2) with 45 degree of freedom = 336.86 (p = 0.00)  Root Mean square error of approximation (RMSEA) = 0.08  Goodness of fit index (GFI) = 0.925  Privacy policy: The variable, importance of privacy policy  (PRIV_POL), aims at providing a contrast to the information  transparency independent variable. It is possible that consumers  have no interest in knowing the details of what information is being  stored and how it is used; rather, they may only be interested in  knowing that the company has a privacy policy. Thus, we control  for the importance of such a privacy policy through the use of a  single three-point Likert-scaled item.  Prior research has shown that demographic variables are associated  with an individual's privacy concern. For example, Culnan (1995)  found that demographics, direct marketing experience, and privacy  concern were significantly associated with individual knowledge  regarding information removal procedures. However, prior research  also suggests that such demographic differences are captured by  both attitudinal and behavioral variables (Azjen and Fishbein 1980).  For this reason, we control for the demographic variables privacy  concern and previous privacy invasion2 when examining consumer  willingness to partake in personalized service and personalized ad  vertising. However, in examining consumer importance of  information transparency as a dependent variable, we control for  gender, education, and income. These variables are controlled for  to determine which factors affect consumer disposition toward  information transparency. The consumer concern over information  transparency is then used as an independent variable in examining  the willingness to share information online.  We did run the model controlling for gender, education, and computer  usage. The results of the variables of interest were unchanged, and the  variables did not add much explanatory power to the models.  Previous privacy invasion: An individual's previous experience can  shape their concern in information sharing. As in previous work  (Culnan 1995), privacy invasion experience was measured using one  variable, namely, whether a participant believed his or her privacy  had been previously invaded (PREV_INV). A total of 73  respondents (19.2 percent) reported being victimized by what  seemed to be an invasion of their privacy online (compared with 21  percent from Culnan's 1995 study and 23 percent from the 1991  Equifax survey).  Privacy concern: Concern for information privacy is a tested,  multidimensional construct (Smith et al. 1996; Stewart and Segars  2002). However, due to the limitations in using secondary data, we  elected instead to control for general privacy concerns, as previously  done by Culnan (1993). Two 4-point Likert-scaled items measured  privacy concern. Both items loaded unambiguously on a single  factor and were combined with the use of factor scores as weights to  form a general privacy concern (PRIV_CONC) scale (r = 0.59, p <  0.0000; Cronbach's alpha = 0.87).  Table 4 contains correlations and descriptive statistics of the all  variables (dependent and scaled independent variables).  Discriminant Validity  The correlation matrix for all items is presented in Table 5. We use  the item-level correlation matrix to test the discriminant validity of  information transparency and privacy concern constructs. Note that  the correlations between items of the same constructs are significant  22 MIS Quarterly Vol. 30 No. 1/March 2006 This content downloaded from  �������������87.63.109.206 on Wed, 17 Jun 2020 11:09:38 UTC�������������  All use subject to https://about.jstor.org/terms  Awad & Krishnan/Personalization Privacy Paradox  Table 4. Descriptive Statistics and Inter-Construct Correlations  INFO  Variable Mean S.D. PSERV PADV FEAT PRIV_POL PREVJNV  PSERV_ 2.12 j 0.79 _| _I PADV 2.53 1.02 0.61 |  I INFO_TRANS I 3.69 ^TTJ -0.12 | -0.17 | ""| j |  I PRIV_POL j 1.58 |a63 -0.01 | -0.08 j 0.43 | | |  | PREVJNV | 1.81 I 0.39 -0.08 | -0.13 | 0.08 } 0.02 | |  | PRIV_CONC j 2.93 | 1.14 | -0.21 ""| -0.21 """" 0.27 | 0.29 [ 0.12 |  Table 5. Descriptive Statistics and Inter-Item Correlations  PRIV_ PRIV_ INFO_TR INFO__TR INFO_.TR INFO_ PREV_ PRIV_  Variable | CONC1 | CONC2 | ANSI [ ANS2 ANS3 | TRANS4 INV POL  PRIV_CONC1 j 1.0000 | I | | '|_  \PRIV_CONC2 j 0.7823 [ 1.0000 | | | '| _  INFO_TRANS1 | 0.2263 0.1755 | 1.000o""| _| ""| |_  | INFO_TRANS2 j 0.2722 j 0.2453 | 0.4671 [ 1.0000 j j | | |  j INFO_TRANS3 | 0.0527""! 0.0678 | 0.4324~~| 0.3985~| 1.0000 | | ""| |  | INFO_TRANS4 \ 0.2450 | 0.2190 | 0.4732 | 0.4224~| 0.5629] 1.000(T| | |  | PREVJNV | 0.1094""! 0.1007 | 0.0736~| 0.1046 | 0.0610 | Q.Q257~| 1.000o""| |  PRIV_POL | 0.2596 0.2900 0.3368 0.3462 0.2762 0.3707 0.0253 1.0000  Table 6. SEM Results for Information  Transparency  Variable INFOJTRANS  PRlV_POL 0.05*  PREVJNV 0.04  PRIV_CONC 0.03*  INCOME 0.04  EDUCATION 0.01  GENDER _0?3_  Notes: Model Fit indices:  Goodness of fit (x2) with 29 degree of freedom = 137.04 (p  = 0.00)  Root mean square error of approximation (RMSEA) = 0.071  Goodness of fit index (GFI) = 0.938  Table 7. LISREL Results for Willingness to  Partake in Online Personalized Service and  Personalized Advertising  Variable | PSERV | PADV  | INFO_TRANS -0.139* -0.07*  PRIV_POL -0.173 -0.141  PREVJNV -0.014 -0.048*  PRIV_CONC ' 0.554 0.007  Notes: Model fit indices:  Goodness of fit (x2) with 30 degree of freedom = 194.96 (p  = 0.00)  Root mean square error of approximation (RMSEA) = 0.089  Goodness of fit index (GFI) = 0.91  MIS Quarterly Vol. 30 No. 1/March 2006 23 This content downloaded from  �������������87.63.109.206 on Wed, 17 Jun 2020 11:09:38 UTC�������������  All use subject to https://about.jstor.org/terms  Awad & Krishnan/Personalization Privacy Paradox  for a sample size of 532 responses. Using the item-level correlation  matrix, discriminant validity is tested by counting the number of  times each item correlates more highly with an item of another  factor than with items of its own theoretical variable. It has been  suggested that if the count is more than one-half the potential  comparisons, then the discriminant validity is acceptable (Campbell  and Fiske 1959). In our case, there are no major violations among  the possible comparisons. The lowest correlation of the items within  the information transparency construct is 0.3985; this correlation is  higher than the highest across-construct correlation of information  transparency with privacy policy (0.3707).  Results and Analysis ^^^ HMl  Hypothesis testing was conducted using a covariance fitting  approach for estimating structural equation models (SEM).  Polychoric correlations were estimated between the dichotomous  item Previous privacy invasion and all other items. Table 6  illustrates the SEM results for the information transparency model.3  As predicted in hypotheses H1 a and H lb, consumer privacy concern  and consumer-rated importance of privacy policy are positively  associated with consumer-rated importance of information  transparency. Note that none of the demographic control variables  are significant, suggesting that the demographic differences are  captured in other attitudinal variables, as suggested by previous  research (Azjen and Fishbein 1980). Another limitation of this study  is that we do not have data on the quality of the firm's privacy  policy or of the quality of the firm's features. Thus, while  consumer-rated importance of online privacy policies and  information transparency remain significant variables to examine,  we recognize that there are limitations in the data set. The results of  the second stage of the model, willingness to partake in online  personalized service and personalized advertising, are shown in  Table 7.4  As predicted in hypothesis H2, consumer-rated importance of  information transparency is negative and significantly associated  with willingness to be profiled online for models, personalized  service, and personalized advertising. However, the demographic  control variable of general online privacy concern (PRIVCONC)  is not significant for either model, thus H4 is not supported. The  demographic variable of previous privacy invasion (PREVINV) is  not significant in the case of willingness to be profiled by a familiar  The model was also estimated using ordinary least squares. The model had  significant explanatory power, as shown by the adjusted R2 value and is  significant (Adj. R2 = 0.1732, Prob. > F = 0.0000).  The model was also estimated using an ordered probit model. The  explanatory power of both the PSERV and PADV models, as shown by the  log likelihood values, were significant (Log Likelihood = -430.845, Prob. >  X2 = 0.0002, and Log Likelihood = -522.824, Prob. > x2 = 0.0000,  respectively).  site fox personalized service', it is, however, positive and significant  in the case of willingness to be profiled by a familiar site for  personalized advertising. All of the significant parameter estimates  are negative. For negative parameters, a larger negative magnitude  suggests a greater likelihood for a decreased willingness to be  profiled for personalized offerings.  Discussion BM_________________I  Academic Findings  Prior privacy invasion experience was significant only in the context  of online advertising, not in the case of online service. Therefore,  users with previous privacy invasion experience have a lower  willingness to be profiled online for personalized advertising.  However, such a result does not hold true with regard to online  service. In the context of utility maximization theory, this research  shows that consumers do, indeed, assign a different value to the two  outcomes. Thus, the difference in benefit values leads to a  difference in significance of various elements of the utility function.  Assuming consumers perceive the value of online service to be  greater than online advertising, they will be more willing to partake  in online personalization. Such greater utility of personalized ser  vice will make previous privacy invasion experience insignificant in  the online service case, but significant in the online advertising case,  as our results suggest.  Effective use of customer information is a critical success factor for  firms online. The challenge for firms, then, becomes collecting and  using information in such a way that consumers feel comfortable.  This study examined, from the consumer perspective, whether  information transparency features are associated with consumer  willingness to take part in online profiling. The results suggest that  firms are facing a paradox, as consumers who value information  transparency features are also less likely to participate in per  sonalized offerings. We speculate that these results reveal that there  is a segment of consumers, the privacy fundamentalists (Westin  1991), that are unwilling to participate in online personalization  regardless of the privacy features implemented by the firm. Con  sequently, we suggest that firms concentrate their efforts on  consumers that are more willing to partake in online personalization  from the beginning.  In focusing on the more pragmatic majority of consumers, firms  must be aware that consumers perceive different value levels in  different outcomes. Our study tested the application of utility  maximization theory and, indeed, consumers associate different  outcomes with different utility levels. Personalized advertising is  largely perceived as less beneficial (McLaughlin 2002) than person  alized service, and therefore previous privacy invasions came to bear  for consumers. Prior work did not reveal a clear association  between previous privacy invasion experience and attitudes toward  secondary information use (Culnan 1993); therefore, this significant  result in the case of online advertising is quite interesting. From a  24 MIS Quarterly Vol. 30 No. 1/March 2006 This content downloaded from  �������������87.63.109.206 on Wed, 17 Jun 2020 11:09:38 UTC�������������  All use subject to https://about.jstor.org/terms  Awad & Krishnan/Personalization Privacy Paradox  managerial perspective, firms may attempt to offer value-added  services to consumers, so that they will overlook previous negative  experiences. In addition, it may be important for firms to commu  nicate the value of the personalization outcome to the consumers in  order to encourage them to partake in online personalization.  Managerial Implications  Consumers that are concerned about having access to their  information within company databases are less willing to share  information. This result suggests that managers may need to focus  on consumers who are intrinsically less privacy sensitive when  offering online personalization. One way for managers to interpret  this would be to assess privacy sensitive customers as a different  segment, and provide customized service to customers who are more  willing to partake in personalization from the outset. By attempting  to provide value to consumers who are more willing to partake in  personalization from the outset, firms are likely to increase  consumer-perceived benefits of personalized service as well as  personalized advertising. One caveat regarding our finding that  consumers who perceived access to information as important are less  willing to share information, is that this result may also be due to the  timing of our data collection. Note that our data was collected at the  infancy of the e-commerce era when firms were at the rudimentary  stages of defining their transparency features and privacy policies.  It is difficult to validate this line of argument with the current data  available to us. We speculate that if high quality data transparency  was provided to consumers in a secure environment with a clear  privacy policy, these consumers may be persuaded to partake in  personalization. So, managers may want to examine the quality of  the data transparency features they provide, as well as the security  of their online environment. A useful avenue for future research,  therefore, may be to study the linkage between information trans  parency features and willingness to partake in personalization while  controlling for the quality of transparency provided by firms and  privacy policies.  While almost all online firms post a privacy policy, it is interesting  to note that our study shows that such policies do not have  significant value to consumers. Upon reflection, this result seems  intuitive, as privacy policies largely go unread by consumers. In  fact, according to Forrester Research, less than 1 percent of the  visitors to six major online travel sites during April 2001 actually  read privacy policies (Regan 2001). Thus, while consumers may  rate a privacy policy as important, few of them actually take note of  the policy when using a site. Thus, firms must consider the residual  benefit of investing in their privacy policy beyond the regulated  requirements.  In future research, we would like to contrast consumer perspectives  with firm implementation levels. While our study was done  completely from the consumer perspective, we are also interested in  examining the interactions between consumer-rated importance of  transparency and level of a firm's investments in transparency.  Future work will give further managerial insights as to which  information technology features add the most value to consumers,  whether information transparency features are used, and to what  degree the features are used.  Limitations  Like other empirical research, the results should be read within its  inherent limitations. As described above, the study was based on  secondary data analysis of a survey designed to measure opinions  toward privacy and information sharing online. Note that all of the  measures are subjective in nature and are prone to measurement  errors that could affect the results of the analysis. Concern for  information privacy is a tested, multidimensional construct (Smith  et al. 1996; Stewart and Segars 2002). However, due to the  limitations of the secondary data, we instead controlled for general  privacy concerns, as previously done by Culnan (1993). Individual  questionnaire items were designed to be unbiased. However, several  items, such as previous privacy invasion, were measured using  single questionnaire items.  We do not address trust as an independent construct explicitly.  While trust is an important construct and has been modeled in prior  privacy models, we focus on constructs surrounding data trans  parency and information policies, and their underlying relationship  with trust. Another limitation of this study is the lack of data on the  quality of the firm's privacy policy; instead, we only determine  whether such a policy exists. In addition, the sample has a slight  bias in favor of more educated, affluent, and Internet-savvy  individuals. Therefore, the results should be viewed with some  caution. The strength of the research is that the data sample is  consistent with other recent work regarding information privacy  (e.g., Stewart and Segars 2002) and that the results are consistent  with theory and enhance our understanding of a given paradox  surrounding online personalization.  Conclusion  Personalized service is becoming increasingly valuable to consumers  and firms (Awad and Krishnan 2002). However, investments in  personalization may come at the cost of consumer privacy. Privacy  has, therefore, become an issue of strategic importance for com  panies operating in the information-centric, networked global econ  omy. In order to provide consumer-driven personalized service,  firms must target consumers who are willing to provide information.  In this paper, we further illuminated an existing dilemma regarding  the application of online personalization; namely, that consumers  who value information transparency features are less willing to be  profiled online for personalized service and advertising. Thus, we  suggest that firms invest their resources toward increasing perceived  value for the consumers who are willing to partake in online  personalization from the outset, as we also found that the perceived  benefit of personalization affects the importance of previous privacy  MIS Quarterly Vol. 30 No. 1/March 2006 25 This content downloaded from  �������������87.63.109.206 on Wed, 17 Jun 2020 11:09:38 UTC�������������  All use subject to https://about.jstor.org/terms  Awad & Krishnan/Personalization Privacy Paradox  invasion on that very willingness. In the case of personalized  service, where benefit is more apparent to consumers, previous  privacy invasions are not significant, as the potential benefit of the  service outweighs the potential risk of a privacy invasion. In the  case of personalized advertising, on the other hand, the benefit is  less apparent and the risk of an intrusion (i.e., e-mail spam) is more  apparent. In such a case, previous privacy invasion is significant.  Thus, companies must focus on reducing such perceived risk  through implementing various online features.  In this study, we have provided results that managers can utilize to  encourage consumer participation in online profiling for  personalized service and advertising. Managers must realize that the  perceived value provided to consumers can affect the degree to  which their previous privacy issues come to bear. Firms must  provide a benefit to offset the potential risk to consumers for sharing  their information with the firm. Future research may examine, over  time, the effectiveness of various information technology features  for increasing consumer-perceived value of online personalization.  Acknowledgments  Financial support for this study was provided in part by the Michael  R. and Mary Kay Hallman Fellowship, the Marcy Maguire  Fellowship, the Information Systems Executive Forum at the  University of Michigan Business School, and the Summer Research  Opportunity Program at the University of Michigan.  "
2," The Privacy Paradox: Personal Information Disclosure Intentions versus Behaviors PATRICIA A. NORBERG, DANIEL R. HORNE, AND DAVID A. HORNE The Privacy Paradox: Personal Information Disclosure Intentions versus Behaviors Impelled by the development of technologies that facilitate collection, distribution, storage, and manipulation of personal consumer informa- tion, privacy has become a ‘‘hot’’ topic for policy makers. Commercial interests seek to maximize and then leverage the value of consumer information, while, at the same time, consumers voice concerns that their rights and ability to control their personal information in the mar- ketplace are being violated. However, despite the complaints, it appears that consumers freely provide personal data. This research explores what we call the ‘‘privacy paradox’’ or the relationship between indi- viduals’ intentions to disclose personal information and their actual personal information disclosure behaviors. With increasingly sophisticated technology, the effectiveness of collect- ing, storing, and analyzing vast amounts of consumer information has cer- tainly increased, especially as related costs have fallen. Marketers who live by the adage ‘‘know thy customer’’ may view this progress as move- ment toward the desired state where knowledge of customers leads to ultra- efficient communication to exactly the right target audiences about product/service offerings, which perfectly match the needs and desires of those same groups (Moon 2000). However, as marketers leverage the ability to collect and analyze ever- greater amounts of consumer information, serious concerns have arisen over the potential erosion of personal privacy (cf. Cavoukian and Hamilton 2002; Whiting 2002; Williams 2002). The popular press has featured pri- vacy concerns as a major negative result of the ‘‘information age,’’ and political forces have sought to transform consumers’ felt deprivation into public policy initiatives. Consumers are constantly faced with the not-so- obvious trade-off between the desire for better products and services that are touted to be the result of more detailed customer profiles on the one Patricia A. Norberg is an assistant professor in the Department of Marketing and Advertising, Quinnipiac University, Hamden, CT (patricia.norberg@quinnipiac.edu). Daniel R. Horne is an assistant professor of marketing at Providence College, Providence, RI (dhorne@providence.edu). David A. Horne is a professor of marketing at California State University – Long Beach, Long Beach, CA (dhorne@csulb.edu). The Journal of Consumer Affairs, Vol. 41, No. 1, 2007 ISSN 0022-0078 Copyright 2007 by The American Council on Consumer Interests 100 THE JOURNAL OF CONSUMER AFFAIRS hand and the privacy encroachment that such disclosure causes on the other. Yet, for all the concern that people express about their personal infor- mation, which could be expected to drive one’s intended and actual disclo- sure, our observations of actual marketplace behavior anecdotally suggest that people are less than selective and often cavalier in the protection of their own data profiles. Few studies have examined this discrepancy between individuals’ intentions to protect their own privacy and how they behave in the marketplace. The purpose of this exploratory study is to investigate whether people say one thing (intend to limit disclosure) and then do another (actually provide personal details) during marketing exchanges. To that end, we report the results of two studies that demonstrate the existence of the privacy paradox and suggest that individuals’ consid- erations of risk and trust help explain why it occurs. Additionally, a discus- sion of public policy is offered, with the goal of stimulating thoughts about how the desires of the public to maintain a sense of privacy may be pre- served in an environment where privacy erosion seems inevitable. BACKGROUND That people are willing to trade personal information for perceived ben- efits is no surprise. For instance, a Web site that provides useful data may require the user to register in order to access the information. It is likely that economists and others would utilize an exchange framework to posit that the information the consumer receives from the Web site in this example is clearly of greater value than that of the information provided by the con- sumer to the site. Yet, this explanation seems less appropriate when we repeatedly witness people giving their phone numbers to clerks while engaged in simple cash transactions at a Sports Authority store. In this case, the benefit may be more difficult to ascertain. As O’Harrow noted in a recent book on surveillance and information collection, consumers ‘‘often will- ingly, even eagerly, part with intimate details of their lives’’ (2005, p. 54). While this seemingly asymmetric exchange, whereby the consumer receives limited value for providing information to a firm, has been noted (cf. Phelps, Nowak and Ferrell 2000; Han and Maclaurin 2002), few researchers have presented empirical evidence of the phenomenon (Sayre and Horne 2000; Spiekermann, Grossklags, and Berendt 2001). The challenge in investigating actual disclosure and the impact thereon of privacy-related measures is threefold. First, privacy perceptions vary widely across populations and even within specific segments (Archer 1980; Culnan 1995; Nowak and Phelps 1992). A closely guarded secret SUMMER 2007 VOLUME 41, NUMBER 1 101 to one may be the chance for an appearance on The Jerry Springer Show for another. So too, certain domains of life are considered more private than others (Wasserstrom 1978; Phelps, Nowak, and Ferrell 2000). For example, Horne and Horne (1998) found that consumers were much more sensitive about the use of medical, financial, and family information than they were about their product and brand consumption or their media usage behavior. White (2004) makes the distinction between information, which when dis- closed, causes a loss of privacy (control) and that which, when disclosed, causes embarrassment. A second challenge faced in trying to understand privacy issues and phe- nomenon is the diversity of measurements used by previous researchers. Measures that have been used when examining privacy include attitudes toward privacy, concern for privacy, privacy-related behavioral intentions, and actual behavior, like disclosing personal information or taking affirma- tive steps to control information usage. This has resulted in some confusion regarding the implications that can be drawn from the literature from both behavioral and policy perspectives. For example, large-scale studies, such as those conducted by Alan Westin throughout the 1990s (cf. Westin 1996), measured privacy in terms of ‘‘concern’’ about the current or future state of respondents’ privacy. The concern measure provides some information about attitudes, though with- out dealing directly with the ambiguous nature of the term privacy. The studies by Westin and others (e.g., Smith, Millberg, and Burke 1996) have also examined concern to show that people have a range of attitudes toward privacy, which might either correlate with other factors like satisfaction with merchant offerings (e.g., Horne and Horne 1997), or which might result from certain antecedent conditions (e.g., Sheehan and Hoy 2000). For instance, Milne and Boza (1999) examined how concern related to trust and developed managerial implications, which suggested that increasing trust mitigated concerns. While the difficulty in sufficiently measuring privacy attitudes is appar- ent, other researchers have attempted to look at privacy-related behavioral intentions. Here, the stated willingness to provide information or to take concrete steps to secure more privacy is investigated as a proxy for the actual behavior that consumers exhibit. For example, Schoenbachler and Gordon (2002) assess the willingness to disclose information as depen- dent upon the level trust in the organization, which is requesting the dis- closure. Along a similar line, Bart et al. (2005) attempt to tie privacy, as a component of trust, to behavioral intention. Their construal of privacy, however, differed from other work in that they measure the perception of privacy-related activities on the part of the Web site (e.g., clarity of 102 THE JOURNAL OF CONSUMER AFFAIRS privacy statement) rather than consumers’ attitudes or concerns about privacy. Finally, research into individuals’ actual disclosure behaviors has been far more limited than that measuring concerns, attitudes, or behavioral inten- tions. Outside of the medical and related health services literature (e.g., Henderson et al. 2002; Potter 2002), studies dealing with methodological issues in data collection (cf. Dillman et al. 1996) and studies in psychology (Jourard 1971a, 1971b; Skotko and Langmeyer, 1977), very few efforts to track actual disclosure behavior are found. In marketing, investigations of actual disclosure behavior and of privacy attitudes and behaviors combined in one study are rare; however, we note two studies that do address these areas. Sayre and Horne (2000) examined actual disclosure and found con- sumers would freely trade personal information in exchange for small dis- counts at a grocery store. The widespread existence of retail and service loyalty programs indicates this practice covers many categories. In the other study, Spiekermann, Grossklags, and Berendt (2001) measured privacy atti- tudes and examined online behavior simultaneously, hypothesizing that the degree to which participants respond to information requests in an online shopping environment would be driven by their privacy concerns and pref- erences. Their study clustered participants into different aggregated privacy profiles based on willingness to provide personal information. In examining the degree to which the clusters differed in their personal information pro- vision when exposed to an online shopping simulation, they found no sig- nificant differences in disclosure levels among the different privacy clusters. They did not, however, investigate factors that might explain why different privacy profiles respond similarly in a behavioral context. CONCEPTUAL FRAMEWORK In the privacy literature, several studies have focused on consumer will- ingness to provide information (e.g., Bart et al. 2005; Schoenbachler and Gordon 2002), but no study up to this point has focused on the degree to which these intentions might influence behavior and what other factors might affect the relationship. Even though only a paucity of direct evidence exists, several streams of research have examined consumer privacy and contribute to the development of the theoretical foundation from which the paradox may be explored. While much of the work in privacy has devel- oped from a legal/rights basis (e.g., Schoeman 1984), consumer privacy work has concentrated on the idiosyncratic nature of the construct and on antecedent conditions that create greater or lesser feelings that the sphere of privacy is being encroached upon. SUMMER 2007 VOLUME 41, NUMBER 1 103 Two notable antecedents, risk and trust, have been investigated with respect to privacy concerns and intentions (Bart et al. 2005; Hoffman, Novak, and Peralta 1999; Horne and Horne 2002; Schoenbachler and Gordon 2002; White 2004) but less so with respect to actual privacy behav- iors. We believe it is important to understand how these two factors might influence one’s intention to disclose and one’s actual disclosure behavior. As suggested by Milne and Boza (1999), we believe trust directly influen- ces behavior. However, we also argue that risk considerations influence one’s intention to disclose but are not strong enough to influence actual behavior. Therefore, we hypothesize that there is a significant difference between one’s intention to disclose and actual disclosure because different frames of reference operate. When an individual is directly asked about intentions (willingness to provide personal information), risk is expected to significantly influence the response, but when an individual is in an actual disclosure situation (asked for information during a marketing exchange), trust as an environmental cue is expected to be relied upon and significantly influence response. Figure 1 reflects how risk and trust might influence both behavioral intentions and actual behavior based on the suggestions of previous research. Figure 2, alternatively, is the conceptual model that underlies this research and reflects how we believe risk and trust truly operate with regard to both behavioral intention and actual behavior. Whereas the more tradi- tional model shows that both risk and trust influence behavioral inten- tions that would then influence actual behavior, we argue that this is not the case. Instead, we argue that behavioral intention is not predictive FIGURE 1 Conceptual Model of Disclosure Based on Previous Research Behavioral Intention (to disclose) Trust Disclosure Behavior Risk 104 THE JOURNAL OF CONSUMER AFFAIRS of actual behavior because risk influences one’s intention to disclose, while a trust heuristic operates in actual disclosure contexts. The following dis- cussion clarifies our positions on trust and risk and the influence of each on intentions and actual disclosure. Behavioral Intention Behavioral intentions are formed based on the combination of an indi- vidual’s attitude, subjective norms, and perceived control of an outcome (cf. Ajzen 1985). Previous findings show intention–behavior correlations of between .41 and .53 (O’Keefe 2002) with the measure being a better predictor of behavior when that behavior is voluntary. Three additional fac- tors also have been shown to influence the strength of the relationship between intention and actual behavior: degree of correspondence between the measure of intention and the measure of behavior (Ajzen and Fishbein 1980), the temporal stability of intention (Ajzen and Fishbein 1980; Sheeran, Orbell, and Trafimow 1999), and the degree to which the behavior was planned (Gollwitzer and Brandstatter 1997; Sheeran, Orbell, and Trafimow 1999). O’Keefe (2002) and others (e.g., Bentler and Speckart 1979; Ouellette and Wood 1998) also argue that there may be other factors that influence behavior independently of intentions. Such factors might in- clude routinization of behavior (Ouellette and Wood 1998) and/or the effects of heuristic processing or information selectivity in the decision process. FIGURE 2 Conceptual Model—Privacy Paradox Behavioral Intention (to disclose) Trust Disclosure Behavior Risk SUMMER 2007 VOLUME 41, NUMBER 1 105 With respect to privacy, it is very possible that one’s stated intentions are not reflective of their behavior because of factors that influence intention and behavior independently, like heuristic processing and routinization of behavior. For example, one’s evaluation of an organization’s trustworthi- ness might be used as a means of evaluating how much and what type of personal information one will give up to that organization. Additionally, the constant and routine requests for information (e.g., postal codes, phone numbers) by commercial interests coupled with the relatively small level of realized losses (FTC 2003) incurred from responding to these requests appear to lead to consumers that readily supply information, potentially due to low perceived risk, even though inquiries regarding intentions to disclose indicate otherwise. Privacy research also suggests that social desirability bias could contam- inate one’s responses to ‘‘willingness to disclose’’ personal information items in such a way that behavioral intentions would not be predictive of actual disclosure behavior (Milne 1997). There is some evidence, how- ever, that such a bias might not be of significant concern to researchers in this area. Norberg (2004) compared what a person said they were willing to disclose to what that person believed others typically disclose in a marketing setting and found no significant difference. Thus, it appears that at a min- imum, people think that their own disclosure behavior is no different from others. Risk Risk, on a general level, has been defined previously as uncertainty resulting from the potential for a negative outcome (Havlena and DeSarbo 1991), and one’s evaluation of risk is influenced by the perceived likelihood of the negative event occurring as well as the perceived severity of that event (Peter and Tarpey 1975). Risk has also been broken down into its dimensionality or type of risk that contributes to an overall perception of risk (Deering and Jacoby 1972; Jacoby and Kaplan 1972). Previous research has shown that risk influences perceptions of privacy. Perceived disclosure consequences (White 2004) are reflective of one’s perception that negative outcomes may be greater than potential benefits when personal information is disclosed. These negative perceptions may affect individuals emotionally, materially, or even physically (Moon 2000). For instance, a past medical condition, if disclosed, may preclude future medical insurance coverage or even employment that could lead to a negative impact on an individual’s health and/or financial status. While disclosure of this nature may significantly impact the individual in a 106 THE JOURNAL OF CONSUMER AFFAIRS negative manner, negative outcomes may also relate to the deterioration of perceived self-image from the discomfort or embarrassment that something an individual wishes to remain secret becomes publicly known. Horne and Horne (2002) showed that concern about these potential negative outcomes had a relatively greater impact on perceptions of privacy than did the level of trust in the organization. Although it appears that consumer concern is certainly driven by risk perceptions, as these studies suggest, today’s mar- keting environment and the lack of consumer recognition of privacy breaches should make one question the effects of risk perceptions on actual behavior. Trust Trust has been defined previously in a variety of ways. For example, Moorman, Deshpande, and Zaltman (1993) defined trust as a willingness to rely on an exchange partner. In consumer privacy and in online con- texts, trust has been measured directly (Garbarino and Lee 2003; Schoen- bachler and Gordon 2002) as well as indirectly operationalized as a company’s reputation (Andrade, Kaltcheva, and Weitz 2002). While noting that trust operates differently in online and offline environments, Bart et al. (2005) develop a substantial list of factors impacting online trust. When trust is made salient to consumers who are asked about their will- ingness to provide personal information to marketers, negative privacy per- ceptions appear not to be reflective of their willingness to provide personal information. Both Schoenbachler and Gordon (2002) and Hoffman, Novak, and Peralta (1999) found that higher levels of trust were related to increased willingness to provide personal information. Also related to trust, Earp and Baumer (2003) examined the effects of brand name status and found that consumers expressed a higher willingness to disclose personally identify- ing and financial information to well-known companies. Milne and Boza (1999) examined the impact of trust on a consumer’s sense of privacy and found that trust was a better means of managing customer data over attempts to reduce concern about privacy. Similarly, Cranor, Reagle, and Ackerman (1999) demonstrated that the level of intended disclosure of personal information was positively related to the level of trust for the organization. Bart et al. (2005) also find a relationship between the pri- vacy component of trust and behavior intention, though their measure of intention addresses intention along other dimensions (i.e., purchase inten- tion, willingness to provide word-of-mouth communications) as well as one element of information disclosure (willingness to register). SUMMER 2007 VOLUME 41, NUMBER 1 107 These findings suggest that organizations may considerably lessen pri- vacy concerns by establishing trusting relationships with consumers, and indeed marketers may leverage environmental cues to make consumers feel comfortable during commercial exchanges. Moreover, consumers typically use heuristics to guide behavior (Bettman 1979; Scholz and Lubell 1998) and will utilize cues in the environment, such as personal characteristics (Allport 1954) or design elements for a Web site (Freeman and Spyridakis 2004) to infer trust. The use of trust as a heuristic (Scholz and Lubell 1998) in disclosure situations might significantly shorten the disclosure decision- making process, thus circumventing effortful cognitive processing. Although it is of significant value for organizations to understand that trust building is important in establishing relationships with consumers, little is known about the effects of trust on willingness versus actual dis- closure, given a particular marketing exchange context. The studies dis- cussed above clearly indicate that trust perceptions influence one’s feelings about privacy (where more trust leads to less privacy concern). However, we believe that in a real exchange situation, where environmen- tal cues used by the organization to establish trust are more salient, con- sumers are more influenced by trust than their willingness indicators would suggest. This may make consumers very vulnerable to unreliable sources that create cues to instill trust in order to carry out unethical busi- ness practices. HYPOTHESES Although consumers seem to be concerned about their privacy as reflected in their intentions to disclose (e.g., measured via ‘‘willingness to provide information’’), anecdotal evidence suggests their behaviors diverge from their intentions to disclose personal details. However, this ‘‘gap’’ has never been measured. The frequent requests for information in commercial interactions and the relatively small level of realized losses incurred from responding to these requests lead to consumers who readily supply information, even though inquiries regarding intentions to disclose indicate otherwise. H1: Individuals will actually disclose a significantly greater amount of personal infor- mation than their stated intentions indicate. When asked about willingness to disclose (behavioral intention), per- ceived risk of disclosing personal information is expected to be salient. Individuals typically have privacy concerns that are formed based on 108 THE JOURNAL OF CONSUMER AFFAIRS external sources of information (e.g., the media), where the external envi- ronment highlights the negative issues associated with privacy or, more specifically, the risks apparent in personal information access and avail- ability. This may drive the intention to disclose because questions asked prime the respondent. For example, the media’s coverage that ‘‘identity theft’’ is reputed to be the fastest growing crime in the United States (Knapp 2004), in addition to credit card ads emphasizing identity protec- tion needs, reflects the negative aspects of privacy breaches that may influence privacy concern. Thus, when individuals are asked about such concerns directly, or about what personal information they would be will- ing to disclose to marketers, consumer reliance on privacy stereotypes and the ease of accessing negative information from memory will influence their intention responses. H2: Risk perceptions will have a significant negative impact on individuals’ stated inten- tions to disclose personal information. During actual disclosure situations, salient environmental cues will likely be relied upon when making disclosure decisions. As marketers strive to create exchange environments that are perceived to be trustworthy, individ- uals are likely to infer trust from the marketers’ cues as they rely on heuristic processing (cf. Bettman 1979; Scholz and Lubell 1998) in these more rou- tine disclosure situations. Thus, trust is expected to influence personal infor- mation disclosure more in actual situations regardless of stated intentions. H3: Trust perceptions will have a significant positive impact on individuals’ actual personal information disclosure. METHOD Study Design To compare disclosure intentions to actual disclosure, two studies were conducted and both used a repeated-measures design, whereby individuals were asked their willingness to disclose specific pieces of information in Phase 1 of each study and then several weeks later were asked to actually provide the same specific pieces of information to a market researcher in Phase 2. T-tests were used to compare the two measures (H1). Addition- ally, in the second study, regression was used to examine the impact of perceived trust and perceived risk on intentions and actual behavior SUMMER 2007 VOLUME 41, NUMBER 1 109 (H2 and H3). The studies took place in classroom settings, and the appro- priate informed consent procedures were followed. Independent Variable Scenarios were used to depict a particular marketing context to which subjects were asked to respond. Scenarios are further described in the Study 1 and Study 2 sections and appear in the appendix. Dependent Variables Dependent variables were operationalized as follows: Behavioral Intention (Phase 1): Total number (sum) of personal items that subject identified they would provide to a marketer. Actual Disclosure (Phase 2): Total number (sum) of personal informa- tion items subjects supplied. The items requested were identical to those in the Behavioral Intention questionnaire. Perceived Risk: One-item measure of how risky subjects felt it was to provide information to the marketer, using a 7-point semantic differen- tial scale anchored by ‘‘not at all risky’’ and ‘‘very risky.’’ Perceived Trust: Three-item scale of how trustworthy, honest, and sin- cere subjects felt the company was on three 7-point Likert-scale items anchored by ‘‘strongly disagree’’ and ‘‘strongly agree.’’ STUDY 1 The goal of Study 1 was to examine initially whether or not we could provide support that the privacy paradox actually exists. A sample of twenty-three part-time, evening program graduate students at a university in the Northeast participated in the experiment. The age range of the sample was 22–40, and the gender split was even. Subjects were initially asked to respond to behavioral intention questions related to disclosing seventeen pieces of personal information, given a particular marketing scenario that was pretested as described below. These subjects then were asked twelve weeks later to actually provide the same seventeen pieces of personal infor- mation to a confederate claiming to represent a commercial enterprise. Thus, individual responses from Phase 1 of each study could be directly matched to the individual responses in Phase 2. See Appendix 1 for the selected scenario and information items. 110 THE JOURNAL OF CONSUMER AFFAIRS Pretests Four marketing scenarios were pretested with the goal of obtaining one scenario that would constitute a believable marketing program for the behavioral condition for an adult group. These scenarios were presented to forty-three graduate students who were asked to rate how trustworthy and risky they felt each situation was with respect to providing personal information. The situation that was selected for the first study, based on risk and trust ratings, was that of a large bank that was introducing a grad- uate student credit card. The bank scenario best demonstrated the character- istics the researchers were seeking—a higher level of trust in the bank coupled with some perception of risk (e.g., providing financial data). The researchers felt this scenario would also be highly believable in Phase 2 where actual data were being collected by ‘‘a large bank.’’ Phase 1 Subjects completed a pencil-and-paper questionnaire to capture respond- ents’ willingness to provide personal information to a large bank. The ques- tionnaire stated that the bank would pay a $20 incentive for providing the information. The compensation was included in the scenario to heighten the perceived benefit of disclosure in the condition, given that we were mea- suring behavioral intention. Respondents were asked to check off from a list of items items they would be willing to provide about themselves. The questions were embedded in a larger survey to add distraction and contrib- ute to the memory decay that was important for the administration of the Phase 2. Phase 2 Twelve weeks following the collection of the intention data, respondents were asked to engage in actual personal information disclosure. The goal of the temporal separation of the two phases was to ensure that participants did not remember their involvement in the first phase. Specifically, in the exe- cution of Phase 2, a confederate visited campus under the guise of carrying out research for a pilot program for a bank. The confederate informed the participants that the bank program was being targeted toward graduate students, and thus the company was visiting college campuses. Next, the situation taken directly from the scenario from Phase 1 was described. The only modification to the scenario in Phase 2 was the lack of monetary incentive—the Phase 1 scenario described some compensation for the SUMMER 2007 VOLUME 41, NUMBER 1 111 information sought, whereas no incentive was offered for the actual pro- vision of information. The monetary incentive was excluded in Phase 2 to reduce motivation for disclosure and to provide a stronger test. The confederate distributed pencil-and-paper data collection booklets. The students were asked to complete the booklets (provide personal infor- mation) and were instructed to leave items blank if they did not want to provide data, instead of filling in erroneous information. By informing sub- jects that they could omit information they were not comfortable providing, we attempted to minimize the risk of information quality confounds. Although one might argue that the classroom setting would have a positive influence on actual disclosure, we believe this is consistent with any envi- ronment where marketers utilize cues to influence consumers’ perceptions of trust (as previously discussed), which positively influences exchanges. We did not, however, want to create an environment that was overly trust- worthy, and thus it was communicated to participants that the ‘‘market researcher’’ was not acquainted with the faculty of the particular school but was visiting a variety of classrooms on campuses across the region. After taking the survey, subjects were debriefed. At this point, the actual identity of the confederate was disclosed, and it was ascertained whether the subjects retained a memory trace of that earlier task. Discussion dem- onstrated that, until prompted to remember, none of the subjects had recalled the Phase 1 task while participating in Phase 2. The researchers also discussed the true nature of the study with participants, and participants were told that they could keep the booklet that they just completed if they did not wish to continue with the study. Data Coding Because the researchers were collecting both identifying and potentially sensitive personal data in Phase 2 of the experiments, care had to be taken during data coding. Responses were recorded and coded by the researcher who was unfamiliar with the particular subject pool. All information items were coded only as either provided (1) or not provided (0), while actual values of information items were not recorded for analysis. Note, however, that actual values were checked by the coding researcher in order to identify any blatantly bogus data (e.g., Donald Duck in the Name Field). Study 1 Results To add support that the privacy paradox exists, Phase 1 and Phase 2 records were matched, and the number of items respondents said they were 112 THE JOURNAL OF CONSUMER AFFAIRS willing to disclose in Phase 1 was compared to the number of items they actually disclosed in Phase 2. The t-tests showed that willingness to dis- close (mean ¼ 8.70, SD ¼ 4.49) was significantly different from actual disclosure (mean ¼ 14.75, SD ¼ 2.22), with t ¼ 27.63, p , .000, and effect size measured by partial eta square ¼ .75. The findings strongly sup- port our argument in that individuals provide significantly greater amounts of personal information than they say they will. Thus, H1 was supported. STUDY 2 In Study 2, undergraduate students were exposed to one of two disclo- sure situations that were pretested, as described below. Subjects were ini- tially asked to respond to behavioral intention questions related to disclosing sixteen pieces of personal information (Phase 1). These subjects then were asked seven weeks later to actually provide the same sixteen pieces of personal information to a confederate claiming to represent a com- mercial enterprise (Phase 2). Trust and risk were also measured in both phases of the Study. See Appendix 2 for scenarios and information items, and Appendix 3 for and trust/risk measures. Pretests In preparation for the experiment, four marketing scenarios were pre- tested with the goal of selecting two scenarios that respondents felt differed significantly with respect to trustworthiness. By using two scenarios that differed on trust, we were given the opportunity to measure the degree to which trust, even for a situation that was deemed less trustworthy, could affect the participants’ behavioral responses to personal information requests and their actual disclosure. Measures appear in Figure 3. In the pretest, the proposed scenarios were presented, during three rounds, to a total of eighty-three undergraduate students from two colleges FIGURE 3 Measurement Model Scenarios Measurement 1 (Phase 1) Measurement 2 (Phase 2) Information Items High-Trust Scenario (Bank) Behavioral Intention to Disclose Perceived Risk Perceived Trust Actual Disclosure Behavior Perceived Risk Perceived Trust 7 highly sensitive 7 moderately sensitive 2 low sensitive Low-Trust Scenario  (Pharma) Behavioral Intention to Disclose Perceived Risk Perceived Trust Actual Disclosure Behavior Perceived Risk Perceived Trust 7 highly sensitive 7 moderately sensitive 2 low sensitive SUMMER 2007 VOLUME 41, NUMBER 1 113 in the Northeast. The students were asked to rate how trustworthy they felt each scenario was with respect to providing personal information. Based on high and low perceived trust scores (Table 1), two of the four scenarios were selected for the actual experiment. The low-trust scenario involved disclosing information to a pharmaceutical company with a poor reputation and the high-trust scenario involved disclosing information to a large rep- utable bank. Phase 1 As part of a larger pencil-and-paper questionnaire that included several distracter tasks, one of the two scenarios (pharmaceutical company/bank) was presented to respondents. They were asked to read the scenario and check off from the list of sixteen personal information items those pieces of information that they would be willing to provide to the company described in exchange for $20. Subjects then responded to the trust and risk perception scale items with respect to disclosing information to either the pharmaceutical company or the bank. Twenty-eight subjects responded to the pharmaceutical scenario and forty subjects responded to the bank scenario, for a total sample of sixty-eight individuals in Phase 1. Phase 2 Seven weeks following the collection of data in Phase 1, the subjects who participated were visited in Phase 2 by a confederate posing as a market researcher representing a commercial company in the same manner as in Study 1. This confederate described the bank credit card or pharmaceutical program that was exactly like the scenario in Phase 1, with the only mod- ification in Phase 2 being a lack of monetary incentive. TABLE 1 Study 2 Pretest Results: Mean (SD) Trust Ratings N Scenario Mean (SD) t-Test Bank versus Pharma (trust) 55 Health club 4.73 (0.91) t ¼ 3.48, p ¼ .001 Bank 4.58 (1.21) Pharma 3.88 (1.10) Reality TV show 3.92 (1.12) 28 Health club 4.43 (0.81) t ¼ 4.95, p ¼ .000 Bank 4.86 (0.90) Pharma 3.43 (1.05) 114 THE JOURNAL OF CONSUMER AFFAIRS Data collection booklets were distributed, and the subjects were asked to complete the booklets (provide personal information). Respondents were instructed to leave items blank if they did not want to provide information instead of filling in erroneous information. To ensure that the subjects who participated in Phase 1 of the project did not retain a memory trace of that task, and to discuss the true nature of the study with participants, debriefing took place after Phase 2 similar to the debriefing during Study 1. As was the case in Study 1, until prompted, none of the subjects had recalled the sce- narios from Phase 1 while participating in Phase 2. Data coding followed the same procedure as in Study 1. Study 2 Results Not all subjects attended both sessions, so fifty-five completed Phase 2 questionnaires were matched to Phase 1 questionnaires (thirty-two partic- ipants in the bank condition and twenty-three participants in the pharma- ceutical condition). Because two different scenarios were used in Study 2, personal data items differ somewhat by scenario to ensure that the data requested were appropriate to the scenario. However, the data items selected are expected to be subjective equivalents (Cranor, Reagle, and Ackerman 1999; Norberg 2004) and therefore scenarios can be analyzed together. Because multiple tests on the same data were performed, a Bonferroni adjustment was made to the significance level, and a signifi- cance level of .01 was used for analysis. Scale reliability was checked for the 3-item trust measure. Cronbach’s alpha for trust in Phase 1 was .96 and in Phase 2 was .95. The t-tests were then performed to check the manipulation of trust in the scenarios, and the mean differences between high and low trust were significant (Table 2). The first and primary focus of the study was to provide evidence that the privacy paradox, or the difference between information actually provided as compared to a willingness to provide, exists (H1). Therefore, the number TABLE 2 Study 2 Condition Manipulation Check Phase/Scenario Mean (SD) Trust t-Statistic Significance Behavioral intention 3.754 .000 Bank 4.60 (1.27) Pharma 3.39 (1.11) Actual behavior 6.514 .000 Bank 5.64 (0.85) Pharma 4.01 (0.84) SUMMER 2007 VOLUME 41, NUMBER 1 115 of items that respondents said they were willing to provide in Phase 1 (behavioral intention) was compared to the number of items they actually provided in Phase 2 (actual behavior). As indicated in Table 3, t-tests showed that willingness to disclose (mean ¼ 10.49, SD ¼ 3.10) was sig- nificantly different from actual disclosure (mean ¼ 15.16, SD ¼ 1.15), with t¼210.02, p, .001. The difference in disclosure was also analyzed inde- pendently for both the bank and the pharmaceutical conditions. Total items intended versus actual disclosure was significantly different for each con- dition, with t ¼ 27.41 (p , .000) and t ¼ 26.66 (p , .000) respectively. H1 was supported as respondents did provide significantly greater amounts of personal information than they say they would. Next, the risk–intention, risk–actual disclosure (H2) and trust–intention and trust–actual disclosure (H3) relationships were examined using regres- sion (Table 4). Risk was tested separately from trust because the two meas- ures exhibit multicollinearity when tested together. According to Hair et al. (1998), if two measures are conceptually different but are likely to covary, then the measures can be regressed separately to remedy the multicollinear- ity problem. The regression result for the risk–intention to disclose relationship was found to be significant (F ¼ 6.973, p ¼ .011), and the result for the risk–actual disclosure relationship was found to be not significant (F ¼ 2.075, p ¼ .157). Thus, we found support for H2 as it does appear that risk is salient when asking for behavioral intention responses but is less so in actual disclosure situations. All relationships were in the expected direction. With regard to H3, it was expected that trust would have a greater pos- itive influence on disclosure behavior than it would on intention to disclose. The respondents’ answers to the 3-item trust scale were used to measure the relationships. None of the relationships between trust and the dependent variables were significant. The lack of support for H3 is contrary to some previous findings that trust significantly impacts an individual’s willingness to provide personal TABLE 3 Study 2 Hypotheses 1 Results: Differences between Intended and Actual Disclosure Condition Mean (SD)—Items Willing to Disclose (Phase 1) Mean (SD)—Items Actually Disclosed (Phase 2) t-Statistic Significance Effect Size Overall 10.49 (3.10) 15.16 (1.15) 210.02 p ¼ .001 .65 Bank 10.38 (3.17) 15.13 (1.21) 27.41 p ¼ .000 .64 Pharma 10.65 (3.07) 15.22 (1.09) 26.66 p ¼ .000 .67 116 THE JOURNAL OF CONSUMER AFFAIRS information but is consistent with the findings reported by Horne and Horne (2002). It is possible that because the companies were unknown to the respondents (no company names were provided) in this study, trust cues were not strong enough to impact one’s actual disclosure. Further, trust and risk may interact in that higher levels of risk may require higher levels of trust for disclosure to take place. This might be the case under certain conditions, where the disclosure context and the type of data (sensitive/per- sonal versus less sensitive/personal) being requested and should be taken into account. Based on the mixed-trust findings, we suggest that trust may not always operate but may be more likely to operate under extreme con- ditions, where very sensitive data or, conversely, innocuous data are being requested from very well-known companies or, conversely, companies that are easily identified as ‘‘questionable.’’ Yet, there are many instances where consumers are being asked for information that is only ‘‘somewhat sensi- tive’’ and are engaging in discourse with companies that do not fit either of the ‘‘well-known’’ or ‘‘suspicious’’ categories. Under these conditions, trust might be difficult to assess and therefore personal disclosure behavior may be better explained by factors other than trust. DISCUSSION The purpose of this exploratory research was to attempt to confirm and explain a particular behavior that the researchers had repeatedly witnessed in the marketplace. However, caution must be exercised in trying to gen- eralize from this work into different less-controlled settings. While we attempted to control a number of outside variables and to provide realistic scenarios, our findings may be, in part, artifacts of the data collection envi- ronment. Even though we believe the classroom setting operated as any other environmental cue, it is possible the setting created too much trust. This overabundance of trust in their educational institution may have given subjects greater confidence that their information would not be used in an inappropriate manner. TABLE 4 Study 2, Hypotheses 2 and 3: Regression Results for Risk and Trust Relationships IV DV R2 df Beta F p Risk Intention to disclose .118 53 2.344 6.973 .011 Actual disclosure .045 45 2.212 2.075 .157 Trust Intention to disclose .026 54 .162 1.428 .237 Actual disclosure .011 45 2.104 .486 .489 Note: IV = ‘‘Independent Variable’’ and DV = ‘‘Dependent Variable’’. SUMMER 2007 VOLUME 41, NUMBER 1 117 Additionally, even though we informed subjects that they should leave information items blank as opposed to entering erroneous data when they were not comfortable supplying personal answers, there exists the possi- bility that data quality may vary. While inspection of the data for blatant misrepresentations was performed, each response was simply recorded as either provided or not. We hypothesized that people say that they are less willing to provide personal information to marketers than they actually provide when a mar- keter directly requests such information from them because perceptions of risk and trust are activated differently when intention measures are taken as compared to actual disclosure settings. In the two studies reported here, we found that the level of actual disclosure significantly exceeded individuals’ intentions to disclose. The difference in level of information provided in all information categories (personally identifying, financial, preferences, demographic, etc.) emphasizes the need to put more research effort into understanding actual behavior. It appears that, in the realm of privacy, behavioral intentions may not be an accurate predictor of actual behavior and other explanations should be sought. Demonstrating the existence of the Paradox itself is but a precursor to the real challenge to discover the antecedent conditions that more fully explain why this phenomenon exists and how these discrepancies between attitu- dinal measures, measures of intention, and behavior can be addressed. The research reported herein provides evidence that, under certain conditions, even people with negative perceptions about disclosing certain personal information will actually produce the information when directly requested. The ability to generalize from this work and the development of informa- tion and educational efforts that will help consumers make informed deci- sions about their provision of personal data will only result if individual antecedents are identified and tested. Contextual factors such as the phys- ical setting, social factors reflecting the relationship between the individual and the person(s) or institution collecting the information, and cognitive factors all may help explain in part the findings presented. Moon’s (2000) work with intimate disclosure to a computer ‘‘being’’ is an interest- ing branch of this type of work. To examine why the gap exists, we hypothesized that risk would signif- icantly influence individuals’ behavioral intentions toward providing per- sonal information, while trust would significantly influence their actual behavior. We found support in Study 2 that risk is activated and signifi- cantly influences individuals’ intentions to provide, while not influencing their actual behavior. However, we did not find support for trust operating as expected. The influence of trust on actual behavior, as opposed to the 118 THE JOURNAL OF CONSUMER AFFAIRS influence on intended behavior that has been the focus in many of the past studies, is still a question. Since there is little research that examines risk and trust in tandem, here is an opportunity to extend this work and develop a better understanding of these two underlying mechanisms. Future research should be geared toward understanding trust and risk interactions not only in extreme cases (well known vs. suspicious companies and very personal vs. innocuous data requests) but also in those more ambiguous cases. Such research would help bring previous findings and the findings in this study together. However, boundary conditions that help explain the independence or interaction of trust and risk are not fully explanatory. Future research, on a practical level, must examine how factors such as the physical environment, the media of data collection and responses to human interaction impact our assessment of trust and risk. Understanding why consumers respond the way they do is of critical importance in this arena where public policy relies upon consumer attitudinal-based perspectives. Surveys of consumers that show a sense of increasing erosion of personal privacy might spur calls for legislative reactions. Yet, all the while, anecdotal evidence and our study suggest con- sumers nonchalantly provide their personal information on a regular basis. In light of this, should policy responses be directed at increasing salience through creating awareness of the potential harm? Or should these deci- sions be removed largely from the consumer’s volition through strict pro- scriptions against data collection? Research attention could be directed toward the effects of awareness/educational initiatives that might better align consumer concern for privacy with their marketplace behaviors. As O’Keefe (2002) noted, explicit planning influences the relationship between intention and disclosure. Consumer-based educational programs might help direct consumers away from shortcut heuristic processing by influencing consumer involvement in their own disclosure decision pro- cesses. At the same time, increased consumer awareness might lead con- sumers to actions that will force commercial parties to improve their offers in exchanges involving consumer information. CONCLUSIONS Consumer privacy has become a ‘‘front burner’’ issue for policy makers over the past decade as countless tales of personal misery made this topic a prime candidate for a myriad of proposed legislative action. At the same time, the current trajectory is certainly for more versus less collection and use of personal information with consumers increasingly feeling like they have ‘‘no place to hide.’’ While policies struggle to keep pace with new SUMMER 2007 VOLUME 41, NUMBER 1 119 technologies, it is fair to question the reliance solely on protective legisla- tion that may be ineffective when individuals willingly disclose personal information. According to Rosenberg, ‘‘the best and most effective way to control use of information, without interfering with the conduct of others, is to prevent it from ever coming into others’ hands’’ (2000, p. 84). It would appear, however, that despite protestations to the contrary, consumers are the conduits of much of this information. From a policy maker’s perspective, this creates a dilemma: should con- sumers be protected from their own chosen behaviors? Should regulatory efforts mandate how information is collected to obviate the need for con- sumers to monitor their own behavior? Our sense is that current movements toward permission-based data collection and usage may address some of the issues raised herein. However, further study in the privacy area is still warranted before additional significant policy changes are made. There must be the realization that, unless consumers make the effort to truly understand what they are granting permission to, and to whom they are giving their personal information, their sense of personal privacy will continue to deteriorate. Especially, as people expand their usage of data- rich transaction channels such as the Internet, the need to comprehend where the data go increases dramatically. We have only to look to the usage of ‘‘privacy policy’’ on various Web sites as an example. These are gen- erally ignored or are imbued with many positive, though nonexistent, attributes by virtue of their mere presence on the site (Milne, Rohm, and Bahl 2004; Miyazaki and Krishnamurthy 2002). The danger is that public policy decisions that only address part of the problem will be made. These may negatively impact commercial entities’ abilities to deliver the goods and services desired by their markets without creating a concomitant real benefit to consumers. Enlisting consumers as the first line of defense to protect their own privacy may well emerge as the most efficient means to ease everyone’s concerns with the data collection race that quickens all around us. APPENDIX 1 Graduate Scenario A large bank, with an excellent reputation for ethical programs, is developing a ‘‘Graduate Student Supreme’’ credit card that will give a per- centage of purchase prices back to the student in gift certificates to the college bookstore and local restaurants, movie passes, and travel vouchers. 120 THE JOURNAL OF CONSUMER AFFAIRS As part of the bank’s analysis of whether to go forward with this program, they are doing research into this student market. They have acquired a list of students and contacted you to take part in the research. You would be com- pensated $20. From the following list, please check which pieces of information you would be willing to provide: h Name h Experience with applying for credit (number of credit cards, loans, etc). h E-mail h Gender h Phone h Attitudes toward lending money to friends h Address h Opinions regarding the use of credit cards h Monthly purchases in categories like food, clothing, entertainment, going out h Age h Hobbies h Attitudes toward saving money h Make, model, and year of car owned h Dining preferences (types of food like American, Italian, Sand- wiches, Tapas, etc.) h Individual monthly income h Total family income h Preference for shopping online for categories like music, books, clothing, travel APPENDIX 2 High-Trust Scenario A large bank, with an excellent reputation for ethical programs, is devel- oping a ‘‘Student Supreme’’ credit card that will give a percentage of pur- chase prices back to the student in gift certificates to the college bookstore and other businesses located on campus. As part of their analysis of whether to go forward with this program, they are doing research into this student market. They have acquired a list of students and contacted you to take part in the research. You would be compensated $20. SUMMER 2007 VOLUME 41, NUMBER 1 121 From the following list, please check which pieces of information you would be willing to provide: h Experience with applying for credit (number of credit cards, loans, etc.) h E-mail h Gender h Phone h Attitudes toward lending money to friends h Address h Opinions regarding the use of credit cards h Monthly purchases in categories like food, clothing, entertainment, going out h Age h Hobbies h Attitudes toward saving money h Make, model, and year of car owned, if any h Dining preferences (types of food like American, Italian, Sand- wiches, Tapas, etc.) h Monthly income h Parents’ income h Preference for shopping online for categories like music, books, clothing, travel Low-Trust Scenario A pharmaceutical company, which has had some recent high-profile fail- ures, has invested significant resources in developing a drug intended for the over-the-counter market, which, when taking after drinking, limits the negative impacts associated with hangovers (i.e., fatigue, headache, nau- sea). As they design a marketing strategy for this product, they are collect- ing research to evaluate if and how it can be successfully introduced. In order to collect the data, they are asking students to sign up to take part in the study. Once accepted, students are asked to fill out a questionnaire (in exchange for $20). From the following list, please check which pieces of information you would be willing to provide: h Religious beliefs h Address 122 THE JOURNAL OF CONSUMER AFFAIRS h Personal health history h Monthly income h Attitudes on drinking and driving h Attitudes toward laws and regulations on drinking/alcoholic consumption h Alcohol consumption (frequency, location, and amount of drinking) h Shopping or setting preferences for categories like food, clothing, health, and beauty items h Prior experience with hangovers (frequency, symptoms, degree of severity of symptoms, duration of symptoms) h Phone h Gender h Monthly purchases in categories like health and beauty, over-the- counter medicines (such as for headaches, indigestion, or allergies) h Dining preferences (like American, Italian, Sandwiches, Tapas, etc.) h E-mail h Hobbies h Age APPENDIX 3 Trust Questions (rated on 7-point Strongly Disagree to Strongly Agree Scale) This company is trustworthy This company is honest This company is sincere Risk Questions (rated on 7-point Semantic Differential Scales) In general, to what degree do you feel it is risky for people to provide the personal information requested to this company? (not at all risky to very risky) "
